{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24l7xzNFOcjn"
      },
      "source": [
        "Install CUDA version of the BLAS libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoywvQjw5IXz",
        "outputId": "d5ba8e19-a01b-4f7b-c17c-0ff2cf377820"
      },
      "outputs": [],
      "source": [
        "!pip install nvidia-cublas-cu11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6RdWhDUflIa"
      },
      "source": [
        "Install the 'vanilla' pennylane package first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFoTdhkBokIC",
        "outputId": "677de0ff-7415-4f1a-e5c7-df29c3f77222"
      },
      "outputs": [],
      "source": [
        "!pip install pennylane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr8Rnnyjfrlc"
      },
      "source": [
        "Now we build the \"lightning\" and \"lightning-gpu\" device code from source. We could probably use pre-packaged versions but this is what i managed to get working. I'll play with using the pre-packaged versions sometime soon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lnQQLM9oT6o",
        "outputId": "abda2051-25c3-483b-a4af-96712ab1c44e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'pennylane-lightning'...\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PennyLaneAI/pennylane-lightning.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfblzK6voeq5",
        "outputId": "a3f37535-8f27-4fe8-9f3a-8d823294673d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"pennylane-lightning\")\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e . -vv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kle7Grjpoq9e",
        "outputId": "eaf3a328-fe6c-4f89-a4f2-129f13fb0fe4"
      },
      "outputs": [],
      "source": [
        "!python -m pip install wheel custatevec-cu11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XQ4rdOoUo0Ay"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import site\n",
        "os.environ[\"CUQUANTUM_SDK\"] = f'{site.getsitepackages()[0]}/cuquantum/lib'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722FyHg9o5Ph",
        "outputId": "b1218be4-8a52-4837-900a-fec84935ed1c"
      },
      "outputs": [],
      "source": [
        "!PL_BACKEND=\"lightning_gpu\" python -m pip install -e . -vv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BCIQ5gKipCpb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAs4SutCfM3T"
      },
      "source": [
        "Note that here we make use of the \"lightning.gpu\" device in order to have the pennylane code access the GPU.  Also a couple of lines to test that it's actually doing what's expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ0ULZQo4iJp",
        "outputId": "c51a7106-5523-4059-dc13-84dae86fa82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dev=<default.qubit device (wires=4) at 0x1ae31a63110>\n",
            "output=[tensor(-0.9852, dtype=torch.float64), tensor(-0.9870, dtype=torch.float64), tensor(-0.8988, dtype=torch.float64), tensor(-0.2443, dtype=torch.float64)]\n",
            "0: ─╭AngleEmbedding(M0)─╭●─╭●──RY(2.43)───────────┤  <Z>\n",
            "1: ─├AngleEmbedding(M0)─╰X─│──╭●─────────RY(1.66)─┤  <Z>\n",
            "2: ─├AngleEmbedding(M0)─╭●─╰X─│──────────RY(1.06)─┤  <Z>\n",
            "3: ─╰AngleEmbedding(M0)─╰X────╰X─────────RY(0.25)─┤  <Z>\n",
            "\n",
            "M0 = \n",
            "tensor([0.7933, 1.4033, 1.6754, 1.4658], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "n_qubits = 4\n",
        "if use_cuda is True:\n",
        "    dev = qml.device(\"lightning.gpu\", wires=n_qubits)\n",
        "else:\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(inputs, weights):\n",
        "    # Original ansatz architecture\n",
        "    '''\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    '''\n",
        "    \n",
        "    # Architecture 3\n",
        "    '''\n",
        "    for i in range(4):\n",
        "        qml.RY(inputs[i], wires=i)\n",
        "    \n",
        "    for i in range(4):\n",
        "        qml.RX(weights[0, 0], wires=i)\n",
        "        qml.RY(weights[0, 1], wires=i)\n",
        "    \n",
        "    for i in range(4):\n",
        "        qml.CNOT(wires=[i, (i + 1) % 4])\n",
        "    \n",
        "    for i in range(4):\n",
        "        qml.RZ(weights[1, 0], wires=i)\n",
        "        qml.RX(weights[1, 1], wires=i)\n",
        "    '''\n",
        "\n",
        "    # Architecture 5\n",
        "    '''\n",
        "    expanded_weights = torch.zeros(2, 4, 3)\n",
        "    expanded_weights[:, :, 0] = weights[:, 0].unsqueeze(0).expand(2, 2).reshape(2, 2).repeat(1, 2)\n",
        "    expanded_weights[:, :, 1] = weights[:, 1].unsqueeze(0).expand(2, 2).reshape(2, 2).repeat(1, 2)\n",
        "    expanded_weights[:, :, 2] = (weights[:, 0] + weights[:, 1]).unsqueeze(0).expand(2, 2).reshape(2, 2).repeat(1, 2) * 0.5\n",
        "\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(inputs[i] * np.pi, wires=i)\n",
        "    \n",
        "    for layer in range(1):\n",
        "        for i, wire in enumerate(range(4)):\n",
        "            qml.RX(expanded_weights[layer, i, 0], wires=wire)\n",
        "            qml.RY(expanded_weights[layer, i, 1], wires=wire)\n",
        "            qml.RZ(expanded_weights[layer, i, 2], wires=wire)\n",
        "        \n",
        "        for i in range(n_qubits):\n",
        "            qml.CNOT(wires=[i, (i + 1) % n_qubits])\n",
        "    '''\n",
        "    \n",
        "    # Architecture 4\n",
        "    '''\n",
        "    flattened_weights = weights.flatten()\n",
        "    \n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(inputs[i], wires=i)\n",
        "    \n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(flattened_weights[i], wires=i)\n",
        "    \n",
        "    for i in range(n_qubits):\n",
        "        qml.CNOT(wires=[i, (i + 1) % n_qubits])\n",
        "    \n",
        "    for i in range(n_qubits):\n",
        "        qml.RZ(flattened_weights[i], wires=i)\n",
        "    \n",
        "    for i in range(n_qubits):\n",
        "        qml.CNOT(wires=[i, (i + 1) % n_qubits])\n",
        "    '''\n",
        "\n",
        "    # Architecture 2\n",
        "    '''\n",
        "    for i in range(4):\n",
        "        qml.RY(np.pi * np.clip(inputs[i], 0.0, 1.0), wires=i)\n",
        "\n",
        "    w_flat = np.reshape(weights, (-1,))  # shape (4,)\n",
        "\n",
        "    for i in range(4):\n",
        "        qml.RY(w_flat[i], wires=i)\n",
        "\n",
        "    # gates: RXX(w0) on (0,1), RYY(w1) on (1,2), RXX(w2) on (2,3), RYY(w3) on (3,0)\n",
        "    qml.IsingXX(w_flat[0], wires=[0, 1])\n",
        "    qml.IsingYY(w_flat[1], wires=[1, 2])\n",
        "    qml.IsingXX(w_flat[2], wires=[2, 3])\n",
        "    qml.IsingYY(w_flat[3], wires=[3, 0])\n",
        "\n",
        "    for i in range(4):\n",
        "        qml.RZ(w_flat[i] * 0.5, wires=i)\n",
        "    '''\n",
        "\n",
        "    # Architecture 1\n",
        "\n",
        "    qml.AngleEmbedding(inputs, wires=range(4), rotation='Y')\n",
        "    \n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.CNOT(wires=[2, 3])\n",
        "    \n",
        "    qml.CNOT(wires=[0, 2])\n",
        "    qml.CNOT(wires=[1, 3])\n",
        "\n",
        "    w_flat = weights.flatten()\n",
        "    \n",
        "    qml.RY(w_flat[0], wires=0)\n",
        "    qml.RY(w_flat[1], wires=1)\n",
        "    qml.RY(w_flat[2], wires=2)\n",
        "    qml.RY(w_flat[3], wires=3)\n",
        "    \n",
        "\n",
        "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(4)]\n",
        "\n",
        "print(f\"{dev=}\")\n",
        "\n",
        "input = torch.from_numpy(np.random.uniform(0, np.pi, (4,))).to(device)\n",
        "weights = torch.from_numpy(np.random.uniform(0, np.pi, (2, 2))).to(device)\n",
        "output = circuit(input, weights)\n",
        "print(f\"{output=}\")\n",
        "drawer = qml.draw(circuit)\n",
        "print(drawer(input, weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h32E5m9VhrIY"
      },
      "source": [
        "### Load MNIST Dataset\n",
        "\n",
        "Note that the images are resized to 14x14 here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y7-OA6WOQj_",
        "outputId": "a03621cc-36aa-41eb-c32d-35688b5cb15a"
      },
      "outputs": [],
      "source": [
        "# Loading of the MNIST/ImageNet dataset\n",
        "transformations = transforms.Compose(\n",
        "    [transforms.Grayscale(),\n",
        "     transforms.Resize([14,14]),\n",
        "     transforms.ToTensor()]\n",
        ")\n",
        "\"\"\"\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = transformations,\n",
        "    download = True,\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = transformations\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "train_data = datasets.ImageNet(\n",
        "    root = 'data/ImageNet',\n",
        "    split = 'train',\n",
        "    transform = transformations\n",
        ")\n",
        "test_data = datasets.ImageNet(\n",
        "    root = 'data/ImageNet',\n",
        "    split = 'val',\n",
        "    transform = transformations\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5vXzkKJgE8C"
      },
      "source": [
        "### Model Hyper-Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "1VHW-I5xOS0v"
      },
      "outputs": [],
      "source": [
        "#Setting of the main hyper-parameters of the model\n",
        "batch_size = 8\n",
        "n_train = batch_size * 125    # Size of the train dataset\n",
        "n_test = batch_size * 25     # Size of the test dataset\n",
        "n_channels = 4\n",
        "initial_lr = 0.003          # Define your initial learning rate\n",
        "num_epochs = 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgAOg2-zgQLe"
      },
      "source": [
        "Note that in the 'quanv' function we need to copy the 'image' and 'weights' data to the CPU memory before converting to numpy arrays. There may be scope for further optimisation here but at the moment it seems that the PyTorch code requires it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "WyFHBoMOOXbu"
      },
      "outputs": [],
      "source": [
        "def quanv(image, weights):\n",
        "    \"\"\"Convolves the input image with many applications of the same quantum circuit.\"\"\"\n",
        "    # PyTorch models generally require a 4D input tensor with the\n",
        "    # dimensions - (batch size, channels, height, width)\n",
        "    # input image shape is (batch_size, 1, 14, 14)\n",
        "    # output shape should be (batch_size, 4, 7, 7)\n",
        "    out = np.zeros((batch_size, 4, 7, 7))\n",
        "    l_image = image.detach().cpu().numpy()\n",
        "    l_weights = weights.detach().cpu().numpy()\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
        "        for j in range(0, 14, 2):\n",
        "            for k in range(0, 14, 2):\n",
        "                # Process a squared 2x2 region of the image with a quantum circuit\n",
        "                q_results = circuit(\n",
        "                    [\n",
        "                        l_image[i, 0, j, k] * np.pi,\n",
        "                        l_image[i, 0, j, k + 1] * np.pi,\n",
        "                        l_image[i, 0, j + 1, k] * np.pi,\n",
        "                        l_image[i, 0, j + 1, k + 1] * np.pi\n",
        "                    ],\n",
        "                    torch.from_numpy(l_weights)\n",
        "                )\n",
        "                # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
        "                for c in range(n_channels):\n",
        "                    out[i, c, j // 2, k // 2] = q_results[c]\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw50zD1qgp6B"
      },
      "source": [
        "Note that in the HybridFunction.forward method we need to copy the output from 'quanv' to GPU memory. That's done by the '.to(device)' call.  Likewise for the initial values of the 'weights' parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "slcAuPHjOkUq"
      },
      "outputs": [],
      "source": [
        "# Custom nn.Module class for handling the quantum convolution\n",
        "class QuantConv(nn.Module):\n",
        "\n",
        "    # The number of layers in the BasicEntanglerLayers instance in\n",
        "    # the quantum convolver\n",
        "    LAYERS = 4\n",
        "\n",
        "    def __init__(self):\n",
        "        super(QuantConv, self).__init__()\n",
        "        # Initialise and register weights\n",
        "        # weights have shape (LAYERS, n_qubits) where LAYERS is the\n",
        "        # number of layers in the BasicEntanglerLayers\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.from_numpy(np.random.uniform(\n",
        "                0, np.pi, (2,2)))).to(device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        expectation_z = quanv(input, self.weights)\n",
        "        x = torch.tensor(expectation_z).to(device)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "dNWwY7CTO7BM"
      },
      "outputs": [],
      "source": [
        "class QuantModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantModel, self).__init__()\n",
        "        self.qconv = QuantConv()\n",
        "        self.fc1 = nn.Linear(4 * 7 * 7, 10)\n",
        "        self.double()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Propagate the input through the CNN layers\n",
        "        x = self.qconv(x)\n",
        "        # Flatten the output from the convolutional layer\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyrIHOtthCnj"
      },
      "source": [
        "The following isn't strictly necessary but it makes for a 'sanity' check on the code. Note that inputs and labels are copied to GPU memory before calling quanv. This is also done in the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUAQmCM6PAEN",
        "outputId": "ddc1dcd3-1fad-4f34-fef4-cd4ae7a07b33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs.shape=torch.Size([8, 1, 14, 14])\n",
            "labels=tensor([6, 8, 8, 8, 8, 2, 0, 3])\n",
            "Repeated labels=tensor([6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2,\n",
            "        0, 0, 0, 0, 3, 3, 3, 3])\n",
            "outputs.shape=(8, 4, 7, 7)\n"
          ]
        }
      ],
      "source": [
        "# Run the quanv function on a batch of images\n",
        "dataset  = train_data\n",
        "train_size = n_train\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "for data in train_loader:\n",
        "    inputs, labels = data\n",
        "    print(f\"{inputs.shape=}\")\n",
        "    print(f\"{labels=}\")\n",
        "    labels = labels.repeat_interleave(n_channels)\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    weights = torch.from_numpy(np.random.uniform(0, np.pi, (2, 2)))\n",
        "    outputs = quanv(inputs, weights)\n",
        "    print(f\"Repeated {labels=}\")\n",
        "    print(f\"{outputs.shape=}\")\n",
        "    #print(f\"{outputs=}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "_NPbZyTNRJ1A",
        "outputId": "9cd832a6-5e41-4639-b050-ad9c73bdb409"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA48AAAPdCAYAAAAqL13zAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAms9JREFUeJzs3Ql8FPX9+P937oMc3AmQmATlEgSRS0AFAaVIVar1+mKJ4FEpiBSrNlpEQUCtKH888KiAWBFQi1CtaE0LlK8gyqUcIkeAEAjhSkIScu//8Zlvkx8Bkp3Ez+7M7L6ej8cQdvaT98zO7ntn3pmZzyfA5XK5BAAAAACAOgTW9SQAAAAAABSPAAAAAABTOPMIAAAAAHCL4hEAAAAA4BbFIwAAAADALYpHAAAAAIBbFI8AAAAAALcoHgEAAAAAbgWLj6usrJTDhw9LdHS0BAQEWL06sDmXyyWnT5+W1q1bS2Agf1vxJnIV9UGuWoM8RX2Rq9YgV+GpPPX54lEVjomJiVavBhwmMzNTEhISrF4Nv0KuoiHIVe8iT9FQ5Kp3kavwVJ46onh87bXX5M9//rNkZ2dLt27d5JVXXpHevXub+l11xlFZuHChREZGuq26zYiLizPVTlXvZkRERJhqFx4ebvqvTWYEB5t/+83GPHDggKl23333nekPsRknTpww1e7QoUN1Pl9WViaff/559ecG3lO1zdu2bStBQUF1tm3WrJmpmB07djTVLiUlxVS75ORkU+3crX8Vs1dDmP1uUsrLy021O3jwoKl2/fv3N32gonMbunuPCwoKjP0AuepdVdv7m2++kaioqDrbfvHFF6Zi/vjjj1r3B2bbDRkyxFS7Rx991FQ7d9vDDtQ+zoyKigpT7bZt2+a2TWFhodx0003kqkW5un//fomJidGyz9qzZ4+pdjk5OabahYaGaj1ONntsEBsbK1blVrnJfbTKG525WlRU5HZ56jvRzD7V9sXjkiVLZNKkSfLGG29Inz59ZPbs2TJ06FDZtWuXtGzZ0vTBmSocGzVqpKVAMruDMHtQ466odVLxaPY16y6Yw8LCTLULCQkx1Y5LnL2vapurnZi7HZnZz67ZHZPZz5nZXHVC8Wj2NZv9vjO7bXR/f5Kr3lW1vdX76O49Mvs9bzZPzX5/m80/s/sNdwfe/lw81uc1k6veVbW91edXV/Fo9v02W/iYzUGz3yVm9xtmc9oTuVVmsp3ZW6fM5qrZeGby1PY3db300kty//33y+jRo+XSSy81ikh1kDJv3jyrVw0AAAAA/Iati8fS0lLZuHFjjUtLVOWsHq9bt+6Cv1NSUiL5+fk1JgAAAACADxePx48fN07HnnuPoXqs7n+8kJkzZxrXMldNdJYDAAAAAD5ePDZEWlqa5OXlVU9mb5wHAAAAADi0w5zmzZsbN/EePXq0xnz1OD4+vtabb83egAsAAAAA8IEzj6oHth49ekh6enqNXj/V4759+1q6bgAAAADgT2x95lFRw3SkpqZKz549jTG91FAdqgtg1ftqfahhOtwN1VGfWGaYPQNqtptys8MT/PTTT6Y7JDKrffv2Wrv/N/tazHbN3rhxY1Pt1NhwurYJPEPd5+xuaIozZ86YilVcXGyqXdOmTbWOG2m2W3Gz3xGeuJpi9erVWsZGrdKkSROt49+6e4/Ndk8Oz1C55e573Oz3vNkx18yO4bZv3z7TQ4GZocaeNeN//ud/xCyrhvUwOx6r2TGbly5d6rYN+1VrqQ4m3R23uhsUvkpWVpapdmaH/jD7PW52CCqzzB4b1GeoukrN7cwObWN227gbqsPsUB6OKB7vuOMOOXbsmDz11FNGJzmXX365rFy58rxOdAAAAAAAnmP74lEZP368MQEAAAAArGHrex4BAAAAAPZA8QgAAAAAcIviEQAAAADgFsUjAAAAAMAtikcAAAAAgFsUjwAAAAAAtygeAQAAAAC+Mc6jDgUFBVJZWaklVlxcnKl2gYHmavOSkhJT7Q4ePGiqXWZmpultYlZ0dLSpdmVlZabahYWFmWoXHGzuIxoREWGqXePGjbW8F/Cc0tJSt7lTWFhoKtbp06dNtXO5XKbabdmyxVS7oqIird8RISEhYpbZ3Prmm2+0LvsPf/iDqXaRkZGm2h0/flzLNoZnHD161O0+ZN++faZi5eTkmGqXm5trql14eLjWfeXzzz9vqt2RI0fErN/+9rem2jVr1sxUuz179phqt3LlSlPtDhw4YKpdQECAljbwnN27d7s9RlL5bEZUVJTWdmb3B2bzwOxy6/OZrKio0Nou0OR+32zNEhoaqiVeUFCQmMWZRwAAAACAWxSPAAAAAAC3KB4BAAAAAG5RPAIAAAAA3KJ4BAAAAAC4RfEIAAAAAHCL4hEAAAAA4BbFIwAAAADALYpHAAAAAIBbweInjh8/LhEREXW2cfd8lcLCQlPtTp48aard6dOnTbU7ceKEqXZxcXGm2sXGxopZR44cMdUuLCxMdGrcuLGpdvn5+abauXuPAwP5e4rVEhISJDi47q+myMhIU7FatGhhqt2pU6dMtSspKRGdwsPDtS93+/btptolJyebateoUSNT7c6cOWOqXcuWLbV8l5SWlpqKA8/o3LmzxMTE1NmmqKjIVKwVK1aYavfTTz+Zaufu+6NKRUWF1v3fggULxKy8vDzT29mMH3/8Uet+32y7w4cPu21DrlpLvZfu9pm5ubmmYu3fv1/rcWiTJk20tqusrDTVrry8XHQrNblPMtvO7DqaPT5wV2uYrW0UjpQBAAAAAG5RPAIAAAAA3KJ4BAAAAAC4RfEIAAAAAHCL4hEAAAAA4BbFIwAAAADALYpHAAAAAIBbFI8AAAAAALcoHgEAAAAAbgWLnzh9+rSUl5fX2SYoKMhUrJMnT5pqd+bMGVPtIiIiTLXr0KGDqXbuXmeVQ4cOiVnBweY+Km3atDHVrqSkxFS7sLAwrdu6srLyZz0Pz+vYsaOEhoZqiZWTkyM6XXzxxabahYeHm2pn9junPtvj+PHjptpFRkaaate4cWNT7bKzs021a9Kkial2sbGxdT4fGMjfPq2kPhcxMTF1thk0aJCpWAkJCVo/YxkZGabauVv/KocPHzbV7siRI2LWhx9+aKrd5s2bTbVr1qyZ1tds9jssICBASxt4jjomdHdcmJWVZSpWenq6qXYFBQVaj39vvPFGU+3uu+8+U+2io6PFrLKyMlPtAk3uk8zu9ysqKky1Ky0tFW9j7wsAAAAAcIviEQAAAADgFsUjAAAAAMAtikcAAAAAgFsUjwAAAAAAtygeAQAAAABuUTwCAAAAANyieAQAAAAAuEXxCAAAAABwK1j8xIkTJyQsLKzONmVlZaZihYaGmmp36aWXmmqXlJRkqt2ZM2dMtdu7d6+pdidPnhSzgoPNfVRatGhhql1UVJSpdvv27TPVLj8/31S7wsLCOp8vKSkxFQee0717d4mIiKizTePGjU3FWrt2ral2sbGxptpFRkaaahcdHW2q3enTp021q8/nsrKy0lS777//3lQ7s9va7PfTnj17TLVr1qzZz8plWM/svrJLly6m2k2ePNlUu1mzZplql5uba6qdu2OHhuSp2dw/duyYqXYBAQGm2hUXF5tqFxQUpK2d2WMreMbhw4clPDy8zjYbNmzQenxpNhfMHluuWLHCVLuQkBAt+5ezNWrUyFS7Jk2aiE55eXmm2gUGBmo5LqnPPpUzjwAAAAAAZxePTz/9tPHXtLOnjh07Wr1aAAAAAOB3bH/ZaufOneWrr76q9yluAAAAAIA+tq/EVLEYHx9v9WoAAAAAgF+z9WWryu7du6V169bStm1bGTlypBw8eNDtTbqq85SzJwAAAACADxePffr0kQULFsjKlStl7ty5kpGRIVdffXWdvZTNnDnT6DmxakpMTPTqOgMAAACAL2pQ8Th16lQpKiq6YFft6jldhg0bJrfddpt07dpVhg4dKv/4xz+MrrWXLl1a6++kpaUZ3dtWTZmZmdrWBwAAAAD8VYOKx2eeeUYKCgrOm68KSvWcp6jxxtq3b1/nOGFqPKaYmJgaEwAAAADAguLR5XJdcEDarVu3StOmTcVTVMGqBiht1aqVx5YBAAAAAPiZva02adKkerxFdQbw7AKyoqLCKO4efPBB0eUPf/iD3HjjjZKUlCSHDx+WKVOmSFBQkNx11131jlVaWnrBgvfcy27NMNtOnSk1o6yszFS7rKwsU+2OHz8uupl9zceOHTPVTr2PZpw8edJUO3WJshnqsmd3nxNYS33W1B+o6hIdHW0qVkJCgql2oaGhptqpKxvMUN+HZlzoCo4LWbNmjZgVHh5uqt3Ro0fFCjt27DDVrq572+vznQTfoW5hMUPd7mLGli1bTLVT/SeYUZ/PZGRkpNZ9pdnjCLPfTcXFxdpeR3l5ualYsI7ZfaC77+X6vudmh9+r64rDs73++uum2kVFRYlZOnOhPswey6v+Ycy4+eabtX1/1at4nD17tnFQN2bMGOPy1LO/UNUHLzk5Wfr27Su6HDp0yCgUT5w4IS1atJCrrrpK1q9fb/wfAAAAAOA99SoeU1NTjZ8pKSnSr18/CQkJEU9avHixR+MDAAAAADxQPFZRxeORI0dqff6iiy5qSFgAAAAAgC8Vj+ry1LruHzR7TT0AAAAAwIeLx82bN593o7aa99JLL8n06dN1rRsAAAAAwMnFY7du3c6b17NnT2ndurX8+c9/lltuuUXHugEAAAAAnDzOY206dOgg3377rc6QAAAAAACnnnnMz8+v8VgN36E60Hn66aelXbt2utYNAAAAAODk4rFx48bndZijCsjExESG1wAAAAAAH9Sg4vHf//53jceBgYHSokULueSSSyQ4uEEhPS48PNyY6hIWFmYqVmlpqal22dnZptpFRUWZamd22557Zrg2JSUlYpbZMT0LCwtNtTtz5ozWdmZfi7v1U50/wVpHjx51m4u6P2fNmjUz1S43N9dUO/WdqPM7Yv369VKfoZTMuPTSS021y8nJMf2+mZGZmWmq3f79+7V8D8N3BAUFmWrXtm1b0z3Hm2G2B/mioiIxy+x3hNnPudn9vu7vMDPfneXl5aZiwTPU9nf3HvTq1ctUrO+//17L93d9j7nMfobM5suxY8dE9/dOucl1NFtrmL2S88YbbzTVTtVpur6/GlTpDRgwoCG/BgAAAABwqAafJty1a5e88sorsnPnTuNxp06dZPz48dKxY0ed6wcAAAAAcGpvqx9//LF06dJFNm7caAzboaZNmzbJZZddZjwHAAAAAPAtDTrz+Nhjj0laWppMnTq1xvwpU6YYz91666261g8AAAAA4NQzj2pYjlGjRp03/+677zaeAwAAAAD4lgYVjwMHDpT//Oc/581fu3atXH311TrWCwAAAADg9MtWb7rpJnn88ceNex6vvPLK6q7kP/zwQ3nmmWdkxYoVNdoCAAAAAPywePzd735n/Hz99deN6ULPKQEBAabHRwIAAAAA+FjxWFlZqX9NAAAAAAC+dc8jAAAAAMC/NOjMo5Kenm5MOTk5552JnDdvnthNYWGhlJeX19mmrKxM6zLN9jwbFBRkql3jxo1NtWvVqpWpdvV5vXl5eabaZWVlmWpXUlJiql1goN6/b7h7zbo/A6i/devWSXBw3V9NSUlJpmK1bt3aVLuTJ0+aapefn691uaGhoabaqVsAzDp+/Lipdjt27DDVTo3ha8bmzZtNtYuLixMdSktLtcSB7zG7r2zZsqWpdnv37jXVLjIyUswyu68pKirSGs/sd0l4eLipdmfOnHHbxt2xFzxLvefu3vfExERTsTp27Giq3YEDB7Qe/5ptFxISYqpdcXGxmGX2eDXYzXFLlf79+5tq95vf/MZUu+joaFPtXC6XWFo8qk5x1BiPPXv2NAqV+hzYAAAAAACcp0HF4xtvvCELFiwwXRUDAAAAAJwtsKGXC/Xr10//2gAAAAAAfKd4vO+++2TRokX61wYAAAAA4DuXraobTd966y356quvpGvXrufdoPrSSy/pWj8AAAAAgFOLx++//14uv/xy4//btm3TvU4AAAAAAF8oHv/973/rXxMAAAAAgG8Uj7fccovbNmrYjo8//vjnrBMAAAAAwMnFY2xsrOfWBAAAAADgG8Xj/PnzxakOHz58Xsc+DS2Oy8vLTbULDDTXme0ll1xiql1ZWZmpdmFhYVrXT2nUqJGpdvv27TPVLjMz01S7oqIiU+3y8vJMtTtz5oyW9xaeExwcbEx1ad26talYF110kal2R48eNdUuPz/fVLuUlBRT7dq1a2eqXd++fcWsr7/+2lS7I0eOaP3eKSgoMNUuISHBVLuKigpt31/wLzExMVrbuVwuU+3cHWM0JKa7fZbZfKlv3oSHh5tqFxQUpO21wjNCQ0ONqS4tWrQwFWvkyJGm2mVnZ5tqt3fvXlPtCgsLTbUzewxn5nNb37YxJr9Pevfubaqd2ZrE7HGyOyUlJabbsvcFAAAAALhF8QgAAAAAcIviEQAAAADgFsUjAAAAAMAtikcAAAAAgFsUjwAAAAAAtygeAQAAAABuUTwCAAAAANyieAQAAAAAuBUsfqKoqEhCQkLqbFNRUWEqVklJial2BQUFptoVFhaaapecnGyqXaNGjUy1O3LkiJi1b98+U+2ysrJMtTt27JipdpWVlVrfE/U50PEZgOdERUW5zdWYmBhTsaKjo021Ky0tNdVu27ZtWnPa7PpdccUVYtbOnTtNtWvatKmpdoMHDzbVrn379qbanT592lS7jIyMOp8nV1GbsLAwUxunefPmpr+TdC5XOXnypKl2QUFBptqZzYf8/Hyt34lmvkdcLpepWPCMwMBAY6rLmTNntH4ex44da6rdli1bTLX797//rfVYtby8XMwye7zRsWNHU+0CAgJMtfvpp59MtQsONlfKlZWV1fl8cXGxOOLM45o1a+TGG2+U1q1bGxvzk08+Oe8L56mnnpJWrVpJRESEDBkyRHbv3m3Z+gIAAACAv7K0eFR/ne/WrZu89tprF3z+hRdekDlz5sgbb7wh33zzjXFGbejQofWqjgEAAAAADr9sddiwYcZ0Ieqs4+zZs+VPf/qT3Hzzzca8hQsXSlxcnHGG8s477/Ty2gIAAACA/7Jthznqfpfs7GzjUtUqsbGx0qdPH1m3bl2d976pa/rPngAAAAAAPlo8qsJRUWcaz6YeVz13ITNnzjSKzKopMTHR4+sKAAAAAL7OtsVjQ6WlpUleXl71lJmZafUqAQAAAIDj2bZ4jI+PN34ePXq0xnz1uOq52rrKVt3qnj0BAAAAAHy0eExJSTGKxPT09Op56v5F1etq3759LV03AAAAAPA3lva2WlBQIHv27KnRSY4aMFQNOnvRRRfJxIkT5dlnn5V27doZxeTkyZONMSFHjBhh5WoDAAAAgN+xtHj87rvv5Nprr61+PGnSJONnamqqLFiwQB577DFjLMgHHnhAcnNz5aqrrpKVK1dKeHh4vZd18uRJCQ6u++VGRkaailVWVmaqndnxKE+fPm2q3bmX8NamcePGWperqO1vdjubUVenRw3Z1oGB5k6il5eX1/l8ZWWlqTjwHJU37t6noqIiU7HMtouOjjbVrqKiwlS7b7/91lS7wYMHm2p36aWXillXX321qXbNmzfXumyz3ydmc0zdglCXgIAAU3Hgf0JDQ021q+sWmIbsUz0xBrW778IqZ86c0RpPDZdmhjpG0/W9Cc/lg67vU7PHyUFBQabaDRgwwFQ7dQLJjB07dphqd+DAATGrf//+Wr8nAjTvu8zmtBqN4uc8b5viceDAgXV+QakNPHXqVGMCAAAAAFjHtvc8AgAAAADsg+IRAAAAAOAWxSMAAAAAwC2KRwAAAACAWxSPAAAAAAC3KB4BAAAAAG5RPAIAAAAA3KJ4BAAAAAC4FSx+Ii8vT4KCgupsU15ebipWWVmZqXZRUVGm2kVERJhqV1JSYqpdYWGhqXaBgeb/dlBQUKB12wQHB2t9LWaX665dZWWlqTiwNlfNfi4qKipMtWvTpo2pdhdffLGpdidPnjTV7vjx46batW/fXsz6xS9+YapdeHi41u+JyMhIU+1cLpfpz4GO9YLvMPv9bPYzZjafze6jAwICxCyzxxtm1WfZOo9fzGxrs+8HPCMmJsbtZ9js59HsPtVsvP3795tq9+OPP5pq17x5c1PtunbtKmYlJCRofc0nTpww1c5s3pj9XjT7PWYGe18AAAAAgFsUjwAAAAAAtygeAQAAAABuUTwCAAAAANyieAQAAAAAuEXxCAAAAABwi+IRAAAAAOAWxSMAAAAAwC2KRwAAAACAW8HiJ/Lz8yUwsO5a2eVymYpVXl5uqp275VUpKioy1S4yMtJUu7y8PK3xlMzMTNPb2YygoCBT7YKDg7Vuw5ycHFPtYJ1Tp065zZ0jR46YitW2bVtT7cLCwky1S0hIMNWudevWptpVVFSYaldYWChmRUVFmWoXHh5uSa6a/Y5o1KiRluXBM9T+0t0+0+w+1ez3t9nPYllZmdY8jYuLM9Vu586dYpbZbWNWaGio1uMXncvVvUzUz+nTp92+B2a/T81+bktLS021y8jIMNXu0KFDWuO52780ZL8faPKYPyIiwlS73Nxcrdva3foVFxebimPEMt0SAAAAAOC3KB4BAAAAAG5RPAIAAAAA3KJ4BAAAAAC4RfEIAAAAAHCL4hEAAAAA4BbFIwAAAADALYpHAAAAAIBbPj/KctWAppWVldoG7DbbTvfAuGYHPja7XLPxPLFtzDLzvtWnnVUDOMP8NjfzXpr97Jod9LawsFBrPLOfR7P5YnYQdSUkJETrss0OzG5225w5c8ZUu5KSElPPk6veVbW98/PzTbfV9fk2+1k0+/1QUFCgdRDu+uzzde/bzLYz+56YjWfmNVd915Cr3lW1vc18NwcHmysHzL6HZnNGd26Zbedu/9KQ76dKkzljdh9odp9qdhsGBgaaWp6Z9zjA5ePZfOjQIUlMTLR6NeAwmZmZkpCQYPVq+BVyFQ1BrnoXeYqGIle9i1yFp/LU54tH9ZeAw4cPS3R0tAQEBFT/xVQVlGoDxcTEiFPxOvRT6XD69Glp3bq127/SQC9y1f7s9J1DrlqDPHUGchXkqv3lO3Sf6vOXraoNUFsFrd4oq98sHXgdesXGxmqOCDPIVeewy3cOuep95KmzkKv+i1x1jhiH7VM5tQIAAAAAcIviEQAAAADgll8Wj2FhYTJlyhTjp5PxOuDr+Izbi6+8H9DLVz4XvvI6fO21QB9f+VzwOqzl8x3mAAAAAAB+Pr888wgAAAAAqB+KRwAAAACAWxSPAAAAAAC3KB4BAAAAAG75XfH42muvSXJysoSHh0ufPn1kw4YN4jRPP/20BAQE1Jg6duwodrdmzRq58cYbpXXr1sY6f/LJJzWeV303PfXUU9KqVSuJiIiQIUOGyO7duy1bX1jL6bnq1DxVyFXUB7lqDfIU9UWuWmONjx3/+lXxuGTJEpk0aZLRTfGmTZukW7duMnToUMnJyRGn6dy5sxw5cqR6Wrt2rdhdYWGhsc3Vl9eFvPDCCzJnzhx544035JtvvpFGjRoZ709xcbHX1xXW8pVcdWKeKuQqzCJXrUOeoj7IVesU+trxr8uP9O7d2zVu3LjqxxUVFa7WrVu7Zs6c6XKSKVOmuLp16+ZyMvXRW7ZsWfXjyspKV3x8vOvPf/5z9bzc3FxXWFiY64MPPrBoLWEVX8hVX8hThVxFXchVeyBP4Q65ag/iA8e/fnPmsbS0VDZu3GicCq4SGBhoPF63bp04jTqdrU5/t23bVkaOHCkHDx4UJ8vIyJDs7Owa709sbKxxuaIT3x80nC/lqq/lqUKuogq5al/kKc5GrtpXhgOPf/2meDx+/LhUVFRIXFxcjfnqsXrTnER9oBYsWCArV66UuXPnGh+8q6++Wk6fPi1OVfUe+ML7g5/HV3LVF/NUIVdRhVy1L/IUZyNX7Svbgce/wVavAOpv2LBh1f/v2rWrcZCalJQkS5culXvvvZdNCtgAeQo4A7kKOAO5ag9+c+axefPmEhQUJEePHq0xXz2Oj48XJ2vcuLG0b99e9uzZI05V9R744vuD+vHVXPWFPFXIVVQhV+2LPMXZyFX7infg8a/fFI+hoaHSo0cPSU9Pr55XWVlpPO7bt684WUFBgezdu9fo4tepUlJSjCQ5+/3Jz883ep1y+vuD+vHVXPWFPFXIVVQhV+2LPMXZyFX7SnHg8a9fXbaquv5PTU2Vnj17Su/evWX27NlG97mjR48WJ/nDH/5gjBejLlU9fPiwMZyBOlNz1113id0Pns8+66LuAduyZYs0bdpULrroIpk4caI8++yz0q5dOyOZJk+ebHQ2MmLECEvXG97nC7nq1DxVyFWYRa5ahzxFfZCr1inwteNfl5955ZVXXBdddJErNDTU6LZ4/fr1Lqe54447XK1atTJeQ5s2bYzHe/bscdndv//9b6OL4nOn1NTU6u6KJ0+e7IqLizO6KB48eLBr165dVq82LOL0XHVqnirkKuqDXLUGeYr6Ilet8W8fO/4NUP9YXcACAAAAAOzNb+55BAAAAAA0HMUjAAAAAMAtikcAAAAAgFsUjwAAAAAAtygeAQAAAABuUTwCAAAAANyieAQAAAAAuEXxCAAAAABwi+IRAAAAAOAWxSMAAAAAwC2KRwAAAACAWxSPAAAAAAC3KB4BAAAAAG5RPAIAAAAA3KJ4BAAAAAC4RfEIAAAAAHCL4hEAAAAA4BbFIwAAAADALYpHP7Rp0ya56aabpGnTphIZGSldunSROXPmWL1aAM6ye/duufPOOyUhIcHI044dO8rUqVOlqKiI7QTYBHkKOAO5qk+wxlhwgC+//FJuvPFG6d69u0yePFmioqJk7969cujQIatXDcB/ZWZmSu/evSU2NlbGjx9v/KFn3bp1MmXKFNm4caMsX76cbQVYjDwFnIFc1Yvi0Y/k5+fLqFGjZPjw4fLRRx9JYCAnngE7eu+99yQ3N1fWrl0rnTt3NuY98MADUllZKQsXLpRTp05JkyZNrF5NwK+Rp4AzkKt6UT34kUWLFsnRo0dl+vTpRuFYWFhoHIwCsN8fepS4uLga81u1amXkbmhoqEVrBqAKeQo4A7mqF8WjH/nqq68kJiZGsrKypEOHDsYlq+rx2LFjpbi42OrVA/BfAwcONH7ee++9smXLFuOSmyVLlsjcuXNlwoQJ0qhRI7YVYDHyFHAGclWvAJfL5dIcEzbVrVs32bNnT/VBqUqmVatWySuvvGJ0zPHBBx9YvYoA/uvZZ5+VGTNmyJkzZ6q3yZNPPmnMB2AP5CngDOSqPtzz6EcKCgqMnhoffPDB6t5Vb7nlFiktLZU333zT6MmxXbt2Vq8mABFJTk6Wa665Rm699VZp1qyZfPbZZ0YxGR8fb3SiA8B65CngDOSqPpx59CNqSI7t27fL6tWrjYPSKmvWrJEBAwbIu+++a3SoA8BaixcvljFjxshPP/1kDNVRZfTo0bJ06VI5ePCgUVACsA55CjgDuaoX9zz6kdatW1+wE46WLVsaP1UPjgCs9/rrrxvD6ZxdOCpqfFZ19cDmzZstWzcA/4c8BZyBXNWL4tGP9OjRw/ipOsw52+HDh42fLVq0sGS9ANSkekWuqKg4b7OUlZUZP8vLy9lkgMXIU8AZyFW9KB79yO233278fOedd2rM/8tf/iLBwcHVvVEBsFb79u2Ns4vqstWzqU6t1FAdXbt2tWzdAPwf8hRwBnJVLzrM8SPqMjh1H9W8efOMMxfqPkfV2+qHH34oaWlp1Ze1ArDWo48+Kp9//rlcffXVRuc46v7GTz/91Jh33333kauADZCngDOQq3rRYY6fUZe9qR4b58+fb1yumpSUJOPGjZOJEydavWoAzrJhwwZ5+umnjTOQJ06ckJSUFElNTZXHHnvMuFIAgPXIU8AZyFV9KB4BAAAAAG5xzyMAAAAAwC2KRwAAAACAWxSPAAAAAAC3KB4BAAAAAG5RPAIAAAAA3KJ4BAAAAAC45fODhVVWVhrjGUZHR0tAQIDVqwObc7lccvr0aWMQ9sBA/rbiTeQq6oNctQZ5ivoiV61BrsJTeerzxaMqHBMTE61eDThMZmamJCQkWL0afoVcRUOQq95FnqKhyFXvIlfhqTz1+eJRnXFUoqKitJ15bN68ueik1k2nnJwc0S0oKEhrvIqKCq3xBgwYoCVOWVmZLFu2rPpzA++p2uaffPKJNGrUSEvMRx99VHS6+uqrtcZr2rSp6LZ//36t8fbt26c13sCBA7XEKSkpkRdeeIFctShP+/fvL8HBeg4htm7dKjq98cYbWuMtWrRIPHFWyM7UvlCX8vJySU9PJ1ctylV1fKQrV7dt2yY6NWnSRGu8Dh06iJ1zQSkuLhad8vLytB2Xb9myxVSe+nzxWFUwqp+6ikfdlzPqLsw8cbml7pjq9LhOISEhWuNxibP3VW1zVTjqKh5151ZYWJjWeOHh4aJbaGio1ni6Djo89ZrJVe+q2t7qc6Hrs6H7PYyMjLT1/sUJxaMnkKvOz1W7H/96Ild1Ky8vt/U2NJOn3NQFAAAAAHCL4hEAAAAA4BbFIwAAAADAN4rH1157TZKTk417Zfr06SMbNmywepUAAAAAwK/YvnhcsmSJTJo0SaZMmSKbNm2Sbt26ydChQz3SoygAAAAAwKHF40svvST333+/jB49Wi699FKjC27Vk9q8efOsXjUAAAAA8Bu2Lh5LS0tl48aNMmTIkBrdBKvH69atq3Xsr/z8/BoTAAAAAMCHi8fjx48bg1bGxcXVmK8eZ2dnX/B3Zs6cKbGxsdVTYmKil9YWAAAAAHyXrYvHhkhLS5O8vLzqKTMz0+pVAgAAAADHCxYba968uQQFBcnRo0drzFeP4+PjL/g7YWFhxgQAAAAA8JMzj6GhodKjRw9JT0+vnldZWWk87tu3r6XrBgAAAAD+xNZnHhU1TEdqaqr07NlTevfuLbNnz5bCwkKj91UAAAAAgHfYvni844475NixY/LUU08ZneRcfvnlsnLlyvM60QEAAAAA+HHxqIwfP96YAAAAAADWsPU9jwAAAAAAe6B4BAAAAAD4xmWrOpSXl0tAQICWWMXFxaLT4cOHtcaLiIgQ3UpKSrTGCw7W+9Hbvn27ljgVFRVa4qDhAgMDjSF6dKhtSJ+Gmj9/vtZ4UVFRotuBAwe0xvvwww+1xvvhhx+0xCktLdUSBw0fSiskJETL5rvyyiu1vg0pKSla482YMUN0e+KJJ7TG++qrr7TGU+Nkwzd888032o5/1bG0TklJSVrjeeIYTo3yYOd1LNW0L6zPenHmEQAAAADgFsUjAAAAAMAtikcAAAAAgFsUjwAAAAAAt7T1WrJixYp6/851113nkc5dAAAAAAA2LR5HjBhRr/aq56fdu3dL27Ztda0CAAAAAMAJl61mZ2cbXdqamSIjI3UuGgAAAADghOIxNTW1Xpeg3n333RITE6Nr8QAAAAAAJ1y2Wt/Bs+fOnatr0QAAAAAAJ/e2WlJSYkwAAAAAAGfTXjz+85//lBtuuEGaNGli3NeoJvV/Ne+rr77SvTgAAAAAgNOKx3fffdcoEmNjY+Xll1+WTz/91JjU/xs3bmw899577+lcJAAAAADASfc8KtOnT5fZs2fLuHHjznvunnvukauuukqmTp0qv/nNb3QuFgAAAADgpDOPBw8elCFDhtT6/ODBg+XQoUM6FwkAAAAAcFrx2LlzZ3nnnXdqfX7evHly6aWX6lwkAAAAAMBpl63OmjVLfvnLX8rKlSuNM5BxcXHG/KNHj0p6errs27dPPvvsM52LBAAAAAA4rXgcOHCgbNu2zRjDcf369ZKdnW3Mj4+Pl2HDhsmDDz4oycnJOhcJAAAAAHBa8aio4vD555/XHRYAAAAA4EvjPAIAAAAAfI/2M4921apVKwkM1FMrHz9+XHRKSkrSGu/HH38U3dSlxzrl5eVpjVdeXq4lTkVFhZY4aDg1nE9wcLCtPhdVoqOjtcYrLCwU3S6//HKt8RYtWqQ1XocOHbTEKS0t1RIHDVNSUiKVlZVaNl+zZs20vg3Hjh3TGu/aa68V3Z577jmt8SZOnKg13vfff68tlvqcZGVlaYuH+klISJCgoCAtm031aaJTbm6u1nh333236OZyubTGK9W878rJyfH66+TMIwAAAADALYpHAAAAAIBbFI8AAAAAAHsVj8uXL5eFCxd6c5EAAAAAAKcVj48//riMHj3am4sEAAAAADitt1VP9AIKAAAAAPDzex5nzpwpvXr1MrrHb9mypYwYMUJ27dpl9WoBAAAAgN/x2JlHNXbLhg0bjPFHzh0LatSoUaZirF69WsaNG2cUkGq8tieeeEKuv/562bFjhzRq1MhDaw4AAAAA8Erx+Pe//11GjhwpBQUFEhMTIwEBAdXPqf+bLR7PHYx0wYIFxhnIjRs3yjXXXKN9vQEAAAAAXrxs9ZFHHpExY8YYxaM6A3nq1Knq6eTJkw2Om5eXZ/xs2rRprW1KSkokPz+/xgQAAAAAsGHxmJWVJRMmTJDIyEhtMdWlrxMnTpT+/ftLly5d6rxPMjY2tnpKTEzUtg4AAAAA4K88UjwOHTpUvvvuO60x1b2P27Ztk8WLF9fZLi0tzThDWTVlZmZqXQ8AAAAA8Efa7nlcsWJF9f+HDx8ujz76qNGxzWWXXSYhISE12t500031ij1+/Hj59NNPZc2aNZKQkFBn27CwMGMCAAAAANiweFTDaJxr6tSp581THeZUVFSYiulyueShhx6SZcuWyapVqyQlJUXLugIAAAAALCoezx2OQ9elqosWLZLly5cbYz1mZ2cb89W9jBEREdqXBwAAAADw4j2PusydO9e4b3HgwIHSqlWr6mnJkiVWrxoAAAAA+BWPjPOoelq95JJLjJ9ne/XVV2XPnj0ye/Zs05etAgAAAAB89Mzjxx9/bAypca5+/frJRx995IlFAgAAAACcVjyeOHHCuC/xXDExMXL8+HFPLBIAAAAA4LTLVtUlqytXrjSG2Djb559/Lm3bthUrtGzZUoKDPfJyf7aDBw9qjXehwt1uHSKVlZVpjaeGhNG1Xjt37tQSCw2zfft2CQzU83etkpISrW+DrvWqMnjwYNEtMTFRa7xvv/1Wa7zPPvtMSxxua/AdhYWFWuP9+c9/1hqvS5cuYnc333yz1nhXXnmltljFxcUyffp0bfFQP1FRUdqOf9u0aaN18+uO9/XXX4tuZkeIqE8+6PT4449riVNaWirvv/++qbYeqaYmTZpkFI7Hjh2TQYMGGfPS09Nl1qxZpu93BAAAAADYh0eKxzFjxhh/8Vd/aZo2bZoxLzk52eg9ddSoUZ5YJAAAAADAgzx2HefYsWONSZ19VGMyqtPmAAAAAABn8vhNgC1atPD0IgAAAAAAHqat94crrrhCTp06Zbr9VVddJVlZWboWDwAAAABwwpnHLVu2yNatW6Vp06am2+vuCREAAAAA4IDLVlW382a7Tw8ICNC5aAAAAACAE4rHjIyMev9OQkKCrsUDAAAAAJxQPCYlJekKBQAAAADw1Q5zAAAAAAC+i+IRAAAAAOAWxSMAAAAAwC2KRwAAAACANcVj27Zt5cSJE+fNz83NNZ4DAAAAADiLR4rH/fv3S0VFxXnzS0pKJCsryxOLBAAAAAA4YagOZcWKFdX//+KLLyQ2Nrb6sSom09PTJTk5WeciAQAAAABOKx5HjBhh/AwICJDU1NQaz4WEhBiF46xZs3QuEgAAAADgtOKxsrLS+JmSkiLffvutNG/eXGd4AAAAAIAvFI9VMjIyPBEWAAAAAOBLxePUqVPrfP6pp57yxGIBAAAAAE4qHpctW1bjcVlZmXE2Mjg4WC6++GJLisf4+HjjvksdTp06JTrpWq8qF+rp9udyuVxa41166aVa47Vp00ZLHNUjMKx12223SVhYmJZYH374oegUHh6uNZ4nLu1/6aWXtMY7evSo1nhDhw7V9j23bds2LbHgW9Sxhk579+4V3Zo2bao13sCBA7XG+/HHH7XFKioq0hYLDfsODwwMtN3nQunUqZPWeLqOHc6ma9tVefLJJ0WnxYsXe/043yPF4+bNm8+bl5+fL/fcc4/86le/8sQiAQAAAABOG+fxQmJiYuSZZ56RyZMne2uRAAAAAACnFY9KXl6eMQEAAAAAnMUjl63OmTPnvOtojxw5Iu+9954MGzbME4sEAAAAADiteHz55ZfPu9m0RYsWkpqaKmlpaZ5YJAAAAADAgxw1zuNzzz1nFJ8PP/ywzJ492yPLAAAAAABYcM9jZmamMf1c3377rbz55pvStWtXLesFAAAAALC4eCwvLzd6VY2NjZXk5GRjUv//05/+ZIz5WF8FBQUycuRIefvtt6VJkyaeWGUAAAAAgLeLx4ceekjeeusteeGFF4wxH9Wk/v/OO+/IhAkT6h1v3LhxMnz4cBkyZIipQd7VmJJnTwAAAAAAG97zuGjRIlm8eHGNnlXV5aaJiYly1113ydy5c03HUnE2bdpkXLZqxsyZM43xJAEAAAAANj/zGBYWZlyqeq6UlBQJDQ01HUfdK6k6x3n//fclPDzc1O+oDnWqxpNUk477LQEAAADA33mkeBw/frxMmzbNuIS0ivr/9OnTjefM2rhxo+Tk5MgVV1whwcHBxrR69WpjHEn1/4qKigsWrjExMTUmAAAAAIANL1tV9zimp6dLQkKCdOvWzZi3detWKS0tlcGDB8stt9xS3fZvf/tbrXFU2x9++KHGvNGjR0vHjh3l8ccfl6CgIE+sPgAAAADAG8Vj48aN5dZbb60xT93vWF/R0dHSpUuXGvMaNWokzZo1O28+AAAAAMBhxeP8+fM9ERYAAAAA4Ev3PA4aNEhyc3PPm6+GzVDP/RyrVq2S2bNn/6wYAAAAAAAbFI+qwFP3N56ruLhY/vOf/3hikQAAAAAAp1y2+v3331f/f8eOHZKdnV39WPWMunLlSmnTpo3ORQIAAAAAnFY8Xn755RIQEGBMF7o8NSIiQl555RWdiwQAAAAAOK14zMjIEJfLJW3btpUNGzZIixYtqp8LDQ2Vli1bWja8xrXXXmsUrzpcdNFFotOmTZu0xtuzZ4/o9qtf/crW8XSN51lQUMAfOCyWlZUlISEhWmKpS+V1uvLKK7XGW7Zsmeh2ww03aI03Y8YM0b2f0EHta4ALUeNAe+qqKl369eunNZ4aGs2u1H4V1lH7wcBAPXepqXHXdfrjH/+oNV5aWpropq6k1Onjjz/WGk+dsPM2rd+wSUlJxs/KykqdYQEAAAAAvjhUx8KFC+t8ftSoUZ5YLAAAAADAScXjww8/XONxWVmZFBUVGZeuRkZGUjwCAAAAgMN4ZKiOU6dO1ZjU9e67du2Sq666Sj744ANPLBIAAAAA4LTi8ULatWsnzz333HlnJQEAAAAA9ue14rGqB7TDhw97c5EAAAAAALve87hixYrzulQ/cuSIvPrqq9K/f39PLBIAAAAA4LTiccSIEeeNQaLGfBw0aJDMmjXLE4sEAAAAADiteGScRwAAAADwLR695/H48ePGBAAAAABwNu3FY25urowbN06aN28ucXFxxqT+P378eOM5AAAAAICfX7Z68uRJ6du3r2RlZcnIkSOlU6dOxvwdO3bIggULJD09Xb7++mtp0qSJzsUCAAAAAJxUPE6dOlVCQ0Nl7969xhnHc5+7/vrrjZ8vv/yyzsUCAAAAAJx02eonn3wiL7744nmFoxIfHy8vvPCCLFu2TOciAQAAAABOKx7VWI6dO3eu9fkuXbpIdna2zkUCAAAAAJxWPKqOcfbv31/r8xkZGdK0aVOdiwQAAAAAOK14HDp0qDz55JNSWlp63nMlJSUyefJk+cUvfqFzkQAAAAAAJ3aY07NnT2nXrp0xXEfHjh3F5XLJzp075fXXXzcKyPfee0/nIgEAAAAATiseExISZN26dfK73/1O0tLSjMJRCQgIkOuuu05effVVSUxM1LlIAAAAAIDTikclJSVFPv/8czl16pTs3r3bmHfJJZdYfq9jv379JCoqSkusZs2aiU5t2rTRGu/EiROi2xVXXCG6/9Cgk/qM6ZCfn68lDhpu0KBBEhERoWUTHjt2TOtbsXHjRlvnlTJ37lyt8XR9b1apqKjQEqfqj5OAp61fv157zMGDB2uNFxys93BOHcPpUlBQoC0WGjYGuzqJo0N5ebnWt6CuflIa4sEHHxTd/vrXv2qNFxYWZst4ap965swZa4rHKk2aNJHevXt7KjwAAAAAwKkd5gAAAAAAfBPFIwAAAADALYpHAAAAAIBbFI8AAAAAALcoHgEAAAAAzi8es7Ky5O677zaGx1Dd91922WXy3XffWb1aAAAAAOBXPDZUh65xhvr37y/XXnutMXZkixYtjLEj1TAgAAAAAADvsXXx+Pzzz0tiYqLMnz+/el5KSkqdv1NSUmJMVRj0HQAAAAB8/LLVFStWSM+ePeW2226Tli1bSvfu3eXtt9+u83dmzpwpsbGx1ZMqPgEAAAAAPlw87tu3T+bOnSvt2rWTL774QsaOHSsTJkyQd999t9bfSUtLk7y8vOopMzPTq+sMAAAAAL7I1petVlZWGmceZ8yYYTxWZx63bdsmb7zxhqSmpl7wd8LCwowJAAAAAOAnZx5btWoll156aY15nTp1koMHD1q2TgAAAADgj2xdPKqeVnft2lVj3k8//SRJSUmWrRMAAAAA+CNbF4+///3vZf369cZlq3v27JFFixbJW2+9JePGjbN61QAAAADAr9i6eOzVq5csW7ZMPvjgA+nSpYtMmzZNZs+eLSNHjrR61QAAAADAr9i6wxzll7/8pTEBAAAAAKxj6zOPAAAAAAB7sP2Zx5/L5XIZPwsKCrTFLCoqEp2Ki4u1xispKRHddL/m06dPa42Xn5+vNU7V5wbeU7XNdeZDeXm56B4+SKeysjKxO93bUFduVcUhV72rans74bOrS2lpqfaYuveBERERWuPpPGYqLCw0fpKr3uWE70jduRUQECC66d5+LpvGq8/nJcBl50+VBocOHZLExESrVwMOk5mZKQkJCVavhl8hV9EQ5Kp3kadoKHLVu8hVeCpPfb54VGcKDh8+LNHR0XX+RUKdcVJFptpoMTEx4lS8jp9HpYP6i3Dr1q0lMJCrur2JXHUmq75zyFVrkKfORa76F3LVmfIdsE/1+ctW1Qaozxkk9UY5uXiswutouNjYWI3vBMwiV53Niu8cctX7yFPnI1f9A7nqbDE23qdyagUAAAAA4BbFIwAAAADALYrH/woLC5MpU6YYP52M1wFfx2fcXnzl/YBevvK58JXX4WuvBfr4yueC1+E9Pt9hDgAAAADg5+PMIwAAAADALYpHAAAAAIBbFI8AAAAAALcoHgEAAAAAblE8AgAAAADc8qvi8bXXXpPk5GQJDw+XPn36yIYNG+ps/+GHH0rHjh2N9pdddpn84x//ECvNnDlTevXqJdHR0dKyZUsZMWKE7Nq1q87fWbBggQQEBNSY1Oux0tNPP33eOqnt7KT3Ap5FrpKrsD/y1B55qrBfRV3IVXvk6tM+cvzrN8XjkiVLZNKkScZYNps2bZJu3brJ0KFDJScn54Ltv/76a7nrrrvk3nvvlc2bNxuFmpq2bdsmVlm9erWMGzdO1q9fL//85z+lrKxMrr/+eiksLKzz92JiYuTIkSPV04EDB8RqnTt3rrFOa9eurbWtHd8LeA65Sq7C/shTe+Wpwn4VF0Ku2itXO/vC8a/LT/Tu3ds1bty46scVFRWu1q1bu2bOnHnB9rfffrtr+PDhNeb16dPH9dvf/tZlFzk5OWqMTtfq1atrbTN//nxXbGysy06mTJni6tatm+n2TngvoA+5ah/kKmpDntoLuYrakKv2McVHjn/94sxjaWmpbNy4UYYMGVI9LzAw0Hi8bt26C/6Omn92e0WdqaytvRXy8vKMn02bNq2zXUFBgSQlJUliYqLcfPPNsn37drHa7t27pXXr1tK2bVsZOXKkHDx4sNa2TngvoAe5Sq7C/shT++Wpwn4V5yJX7Zeru33g+Ncvisfjx49LRUWFxMXF1ZivHmdnZ1/wd9T8+rT3tsrKSpk4caL0799funTpUmu7Dh06yLx582T58uXy17/+1fi9fv36yaFDh8Qq6n5TdS/mypUrZe7cuZKRkSFXX321nD592pHvBfQhV8lV2B95aq88Vdiv4kLIVXvlah8fOf4NtnTpaDB176O65rmua6WVvn37GlMVlTidOnWSN998U6ZNm2bJOzBs2LDq/3ft2tVIJvWXoaVLlxrXdQO+hFwF7M/JeaqwX4W/cHKuDvOR41+/KB6bN28uQUFBcvTo0Rrz1eP4+PgL/o6aX5/23jR+/Hj59NNPZc2aNZKQkFCv3w0JCZHu3bvLnj17xC4aN24s7du3r3Wd7PxeQC9y9f8hV2FX5Km981RhvwqFXLV3rjZ26PGvX1y2GhoaKj169JD09PTqeer0tXp89l8lzqbmn91eUT2c1tbeG1wul1E4Llu2TP71r39JSkpKvWOoy3d/+OEHadWqldiFuidz7969ta6THd8LeAa5+v+Qq7Ar8tTeeaqwX4VCrto7Vwucevzr8hOLFy92hYWFuRYsWODasWOH64EHHnA1btzYlZ2dbTz/m9/8xvXHP/6xuv3//u//uoKDg10vvviia+fOnUYPSSEhIa4ffvjBstcwduxYo+fUVatWuY4cOVI9FRUVVbc593U888wzri+++MK1d+9e18aNG1133nmnKzw83LV9+3aLXoXL9cgjjxivISMjw9jOQ4YMcTVv3tzoPdYp7wU8h1wlV2F/5Kl98lRhv4rakKv2ydVHfOT412+KR+WVV15xXXTRRa7Q0FCj6+L169dXPzdgwABXampqjfZLly51tW/f3mjfuXNn12effeaykqr1LzSp4Thqex0TJ06sfs1xcXGuG264wbVp0yaXle644w5Xq1atjHVq06aN8XjPnj2Oei/gWeQquQr7I0/tkacK+1XUhVy1R67e4SPHvwHqH2vPfQIAAAAA7M4v7nkEAAAAAPw8FI8AAAAAALcoHgEAAAAAblE8AgAAAADcongEAAAAALhF8QgAAAAAcIviEQAAAADgFsUjAAAAAMAtikcAAAAAgFsUjwAAAAAAtygeAQAAAABuUTwCAAAAANyieAQAAAAAuEXxCAAAAABwi+IRAAAAAOAWxSMAAAAAwC2KRwAAAACAWxSPAAAAAAC3KB790KZNm+Smm26Spk2bSmRkpHTp0kXmzJlj9WoBOMvu3bvlzjvvlISEBCNPO3bsKFOnTpWioiK2E2AT5CngDOSqPsEaY8EBvvzyS7nxxhule/fuMnnyZImKipK9e/fKoUOHrF41AP+VmZkpvXv3ltjYWBk/frzxh55169bJlClTZOPGjbJ8+XK2FWAx8hRwBnJVL4pHP5Kfny+jRo2S4cOHy0cffSSBgZx4Buzovffek9zcXFm7dq107tzZmPfAAw9IZWWlLFy4UE6dOiVNmjSxejUBv0aeAs5ArupF9eBHFi1aJEePHpXp06cbhWNhYaFxMArAfn/oUeLi4mrMb9WqlZG7oaGhFq0ZgCrkKeAM5KpeFI9+5KuvvpKYmBjJysqSDh06GJesqsdjx46V4uJiq1cPwH8NHDjQ+HnvvffKli1bjEtulixZInPnzpUJEyZIo0aN2FaAxchTwBnIVb0CXC6XS3NM2FS3bt1kz5491QelKplWrVolr7zyitExxwcffGD1KgL4r2effVZmzJghZ86cqd4mTz75pDEfgD2Qp4AzkKv6cM+jHykoKDB6anzwwQere1e95ZZbpLS0VN58802jJ8d27dpZvZoARCQ5OVmuueYaufXWW6VZs2by2WefGcVkfHy80YkOAOuRp4AzkKv6cObRj6ghObZv3y6rV682DkqrrFmzRgYMGCDvvvuu0aEOAGstXrxYxowZIz/99JMxVEeV0aNHy9KlS+XgwYNGQQnAOuQp4Azkql7c8+hHWrdufcFOOFq2bGn8VD04ArDe66+/bgync3bhqKjxWdXVA5s3b7Zs3QD8H/IUcAZyVS+KRz/So0cP46fqMOdshw8fNn62aNHCkvUCUJPqFbmiouK8zVJWVmb8LC8vZ5MBFiNPAWcgV/WiePQjt99+u/HznXfeqTH/L3/5iwQHB1f3RgXAWu3btzfOLqrLVs+mOrVSQ3V07drVsnUD8H/IU8AZyFW96DDHj6jL4NR9VPPmzTPOXKj7HFVvqx9++KGkpaVVX9YKwFqPPvqofP7553L11VcbneOo+xs//fRTY959991HrgI2QJ4CzkCu6kWHOX5GXfamemycP3++cblqUlKSjBs3TiZOnGj1qgE4y4YNG+Tpp582zkCeOHFCUlJSJDU1VR577DHjSgEA1iNPAWcgV/WheAQAAAAAuMU9jwAAAAAAtygeAQAAAABuUTwCAAAAANyieAQAAAAAuEXxCAAAAABwy+f7e6+srDSGpIiOjpaAgACrVwc253K55PTp08Y4emowdngPuYr6IFetQZ6ivshVa5Cr8FSe+nzxqArHxMREq1cDDpOZmSkJCQlWr4ZfIVfREOSqd5GnaChy1bvIVXgqT32+eFRnHJU//OEPEhYWpiXm9ddfLzp98cUXWuPNmDFDdOvRo4fWeGPGjNEar7CwUEuc4uJieeqpp6o/N/Ceqm3esWNHCQoK0hKzc+fOotNFF12kNV6zZs1Et/T0dK3xjhw5ojVeixYttMQpLy+XtWvXkqsW5Wn79u215Wnv3r1Fp0GDBmmN9+6774on/sqvk8oHnf7zn/+IbuxXvatqew8fPlxCQkK0xFRnpXS6+OKLbZ0Hyr59+7TGi4iI0BpP13tbUlIic+bMMZWnPl88Vl2qqgrH8PBwLTGjoqJEJ13r5Um6DhI8lTzq8gyduMTZ+6q2ufqs6fq8hYaGik66/gDlydwPDg62de7rXj9y1buckKeRkZG2/sx6onh0AnLVmu2tigtdBYbufaDuY0FPFI+6X3OY5ni63tv65Ck3dQEAAAAA3KJ4BAAAAAC4RfEIAAAAAHCL4hEAAAAA4BvF42uvvSbJyclG5xJ9+vSRDRs2WL1KAAAAAOBXbF88LlmyRCZNmiRTpkyRTZs2Sbdu3WTo0KGSk5Nj9aoBAAAAgN+wffH40ksvyf333y+jR4+WSy+9VN544w2jG+558+bVOk5Jfn5+jQkAAAAA4MPFY2lpqWzcuFGGDBlSPS8wMNB4vG7dugv+zsyZMyU2NrZ6SkxM9OIaAwAAAIBvsnXxePz4camoqJC4uLga89Xj7OzsC/5OWlqa5OXlVU+ZmZleWlsAAAAA8F3B4mPCwsKMCQAAAADgJ2cemzdvLkFBQXL06NEa89Xj+Ph4y9YLAAAAAPyNrYvH0NBQ6dGjh6Snp1fPq6ysNB737dvX0nUDAAAAAH9i+8tW1TAdqamp0rNnT+ndu7fMnj1bCgsLjd5XAQAAAADeYfvi8Y477pBjx47JU089ZXSSc/nll8vKlSvP60QHAAAAAODHxaMyfvx4YwIAAAAAWMPW9zwCAAAAAOyB4hEAAAAA4BuXreqQn58vJSUlWmKpey51mjFjhtZ4qlMh3T7//HOt8U6fPq01Xnl5uZY4ZWVlWuKg4TIyMiQgIEDLJhw8eLDWt+LTTz/VGi8iIkJ0a9asmdZ4W7du1RqvZcuWWuKonrdhnZtvvlnCw8O1xIqJiRE7f2Yff/xx0e3ZZ5/VGk/1DaHTyJEjtcVS+9WlS5dqi4f6ufbaa7Xta06ePKl18zdt2lRrvM2bN4snRn7QqbCwUGs8XcetpaWlptty5hEAAAAA4BbFIwAAAADALYpHAAAAAID37nmcM2dOvX9n9OjREh0drWsVAAAAAAB2Lx4nTpwoCQkJEhQUZKp9Zmam/PKXv6R4BAAAAAB/6231u+++M92THmccAQAAAMAP73mcMmWKREVFmW7/xBNPaO+iFwAAAABg8zOPqnisj7S0NF2LBgAAAAB4GL2tAgAAAADsVTzu3LlT2rZt681FAgAAAACcVjyWlpbKgQMHvLlIAAAAAIDdeludNGlSnc8fO3ZM5+IAAAAAAE4sHv+//+//k8svv1xiYmIu+HxBQYHOxQEAAAAAnFg8XnLJJfL73/9e7r777gs+v2XLFunRo4fORQIAAAAAnHbPY8+ePWXjxo21Ph8QECAul0vnIgEAAAAATjvzOGvWLCkpKan1+W7dukllZaXORQIAAAAAnFY8xsfH6wwHAAAAAPDHoToAAAAAAM5E8QgAAAAA8O5lq3amhg8JDw+35eW5n3zyidZ4f/zjH0W3J554Qmu89PR0rfF+/etfa4lTWFioJQ4a7sYbb5TQ0FAtm3DdunVa34qkpCSt8Q4cOCC66dp2VR544AGt8QID+ZulL/jmm28kOFjPIcTKlStFp/vuu09rvD//+c+iW2RkpNZ4vXr10hovKCjIlrFQf6NGjap1CL36qqtTTDvsU+fNmye6FRcX23of2KlTJ6+vF3txAAAAAIBbFI8AAAAAAHsVj8uXL5eFCxd6c5EAAAAAAKcVj48//riMHj3am4sEAAAAADitw5wff/zRm4sDAAAAAGjCPY8AAAAAAOvOPObm5sqGDRskJydHKisrz+s22IyZM2fK3/72N+OMZUREhPTr10+ef/556dChg4fWGgAAAADgteLx73//u4wcOVIKCgqMsWUCAgKqn1P/N1s8rl69WsaNG2eMX1ReXm6MNXj99dfLjh07pFGjRp5YdQAAAACAt4rHRx55RMaMGSMzZsz4WQPhnjtw8IIFC6Rly5bGIKXXXHPNBX+npKTEmKrk5+c3ePkAAAAAAA/e85iVlSUTJkz4WYXjheTl5Rk/mzZtWuelrrGxsdVTYmKi1nUAAAAAAH/kkeJx6NCh8t1332mNqe6bnDhxovTv31+6dOlSa7u0tDSjyKyaMjMzta4HAAAAAPgjbZetrlixovr/w4cPl0cffdS4N/Gyyy6TkJCQGm1vuummesdX9z5u27ZN1q5dW2e7sLAwYwIAAAAA2LB4HDFixHnzpk6det481WFORUVFvWKPHz9ePv30U1mzZo0kJCT8rPUEAAAAAFhYPJ47HIcOLpdLHnroIVm2bJmsWrVKUlJStC8DAAAAAGDhOI86qEtVFy1aJMuXL5fo6GjJzs425quOcNS4jwAAAAAAB3eYo3panTNnznnzX331VaPTG7Pmzp1rdHozcOBAadWqVfW0ZMkSzWsMAAAAAPB68fjxxx8bvaKeq1+/fvLRRx/V67LVC0333HOP5jUGAAAAAHi9eDxx4oRxaem5YmJi5Pjx455YJAAAAADAacXjJZdcIitXrjxv/ueffy5t27b1xCIBAAAAAE7rMGfSpEnG8BrHjh2TQYMGGfPS09Nl1qxZMnv2bLGCGnPy3PEmG+rJJ58Unaq2kS433nij6HbmzBmt8W655Rat8Zo3b64lTnh4uJY4aLgDBw5IcHCwLd/PrKwsrfFefvll0W3y5Mm2zK0qjRs31hJHDfmk9jFwvl/84hda43355Zda41133XWiW1FRkdZ4F110kdZ4p06d0harrKxMWyzU36ZNmyQqKkrLpvvHP/6h9S2o79B97tx9992iW6NGjbTG++6777TGGzp0qJY4hYWF8s4771hXPI4ZM0ZKSkpk+vTpMm3aNGNecnKy0QHOqFGjPLFIAAAAAIATh+oYO3asMam/DKthNXT91QMAAAAA4IPjPLZo0cLTiwAAAAAAOKXDnCuuuKJe18hfddVV2u8fAgAAAADY/Mzjli1bZOvWrdK0aVPT7dV9kQAAAAAAP7tsdfDgweJyuUy1DQgI0LloAAAAAIATiseMjIx6/05CQoKuxQMAAAAAnFA8JiUl6QoFAAAAAPDVDnMAAAAAAL6L4hEAAAAA4BbFIwAAAADALYpHAAAAAIA1xWPbtm3lxIkT583Pzc01ngMAAAAAOItHisf9+/dLRUXFefNLSkokKyvLE4sEAAAAADhhqA5lxYoV1f//4osvJDY2tvqxKibT09MlOTlZ5yIBAAAAAE4rHkeMGGH8DAgIkNTU1BrPhYSEGIXjrFmzdC4SAAAAAOC04rGystL4mZKSIt9++600b95cZ3gAAAAAgC8Uj1UyMjI8ERYAAAAA4EvF49SpU+t8/qmnnvLEYgEAAAAATioely1bVuNxWVmZcTYyODhYLr74YopHAAAAAHAYjxSPmzdvPm9efn6+3HPPPfKrX/1KrHDllVdKRESEllh/+ctfRKehQ4dqjVdQUCC6HTlyRGu8vn37ao0XFxenJY76nMJaaozYoKAgLbFatWolOiUkJGiNd/LkSdFN/YFOJzU+rx1ztby8XPbs2aMlFnzLjBkztMZTHf7p1qRJE63xcnJybPvdpHIV1lHHb5GRkVpi/frXvxad3n//fa3x9u7dK7odPnxYa7w//vGPHj1h11DFxcXWjvN4ITExMfLMM8/I5MmTvbVIAAAAAIAmXiselby8PGMCAAAAADiLRy5bnTNnTo3HLpfLOG3+3nvvybBhwzyxSAAAAACA04rHl19+ucbjwMBAadGihaSmpkpaWponFgkAAAAA8CDGeQQAAAAAWH/PY2ZmpjHp8Nxzz0lAQIBMnDhRSzwAAAAAgIXFo+qWWfWqGhsbK8nJycak/v+nP/3JGPOxIb799lt58803pWvXrtrXFwAAAABgQfH40EMPyVtvvSUvvPCCMeajmtT/33nnHZkwYUKDxi0cOXKkvP3229rHRgIAAAAAWHTP46JFi2Tx4sU1elZVZwwTExPlrrvukrlz59Yr3rhx42T48OEyZMgQefbZZ+tsW1JSYkxVGPQdAAAAAGxaPIaFhRmXqp4rJSVFQkND6xVLFaGbNm0yLls1Y+bMmfLMM8/UaxkAAAAAAAsuWx0/frxMmzatxhlA9f/p06cbz5mlOtp5+OGH5f3335fw8HBTv6OGAsnLy6uedHXWAwAAAAD+zCNnHtU9junp6ZKQkCDdunUz5m3dulVKS0tl8ODBcsstt1S3/dvf/lZrnI0bN0pOTo5cccUV1fMqKipkzZo18uqrrxoFaVBQ0HlnPdUEAAAAALB58di4cWO59dZba8xT9zvWlyo0f/jhhxrzRo8eLR07dpTHH3/8vMIRAAAAAOCg4nH+/Pla4kRHR0uXLl1qzGvUqJE0a9bsvPkAAAAAAIfd8zho0CDJzc09b77q+VQ9BwAAAABwFo+ceVy1apVxf+O5iouL5T//+c/Pjg0AAAAAcHDx+P3331f/f8eOHZKdnV2jo5uVK1dKmzZtdC4SAAAAAOC04vHyyy+XgIAAY7rQ5akRERHyyiuv6FwkAAAAAMBpxWNGRoa4XC5p27atbNiwQVq0aFH9XGhoqLRs2ZIeUgEAAADA34vHpKQk42dlZaXYzYkTJ7SN/xgYqLefoQEDBmiNp3qp1e3ssTZ1UH9c0Ombb77REufMmTNa4qDhOnToICEhIVo2oRonVqfY2Fit8d5//33RbdmyZVrj3X777bb8fiorK9MSB75n7dq1YneRkZFa46lxr3W6UL8VDVVeXq4tFupPHZPrOi5ft26d1rdADcmn05w5c0S3v//971rjde/eXWu8qKgoLXHqM/yhRzrMWbhwYZ3Pjxo1yhOLBQAAAAB4iEeKx4cffvi8vxAXFRUZl66qv7ZRPAIAAACAs3hknMdTp07VmAoKCmTXrl1y1VVXyQcffOCJRQIAAAAAnFY8Xki7du3kueeeO++sJAAAAADA/rxWPCrBwcFy+PBhby4SAAAAAGDXex5XrFhR47EavuPIkSPy6quvSv/+/T2xSAAAAACA04rHESNG1HgcEBBgjPk4aNAgmTVrlicWCQAAAABwWvFox3EeAQAAAAA2vefx+PHjxgQAAAAAcDbtxWNubq6MGzdOmjdvLnFxccak/j9+/HjjOQAAAACAn1+2evLkSenbt69kZWXJyJEjpVOnTsb8HTt2yIIFCyQ9PV2+/vpradKkic7FAgAAAACcVDxOnTpVQkNDZe/evcYZx3Ofu/76642fL7/8ss7FAgAAAACcdNnqJ598Ii+++OJ5haMSHx8vL7zwgixbtkznIgEAAAAATise1ViOnTt3rvX5Ll26SHZ2ts5FAgAAAACcVjyqjnH2799f6/MZGRnStGlTnYsEAAAAADiteBw6dKg8+eSTUlpaet5zJSUlMnnyZPnFL36hc5EAAAAAACd2mNOzZ09p166dMVxHx44dxeVyyc6dO+X11183Csj33ntP5yIBAAAAAE4rHhMSEmTdunXyu9/9TtLS0ozCUQkICJDrrrtOXn31VUlMTNS5SAAAAACA04pHJSUlRT7//HM5deqU7N6925h3ySWXcK8jAAAAADiY9uKxSpMmTaR3795iF9u3b5eQkBAtsSorK7XE8VQ8T3RKpC5H1umvf/2r1nhXXnml1niwTl5engQH6/lq6tSpk+h06NAhrfE88R2p+/vk6NGjWuPpem/Ly8u1xIH1qq5S0qWsrExrvLZt24onvud0Kiws1BqvoqLClrFQf2qUg4iICFt+7w4ZMkRrvH379oluaox6nQIDtXY3Y1zd6e04el8BAAAAAMAnUTwCAAAAANyieAQAAAAAuEXxCAAAAABwi+IRAAAAAOD84jErK0vuvvtuadasmdFb1GWXXSbfffed1asFAAAAAH7FY0N16KDGiuzfv79ce+21xtiRLVq0MMaOVMOAAAAAAAC8x9bF4/PPPy+JiYkyf/786nkpKSmWrhMAAAAA+CNbX7a6YsUKY3D62267TVq2bCndu3eXt99+u87fKSkpkfz8/BoTAAAAAMCHi8d9+/bJ3LlzpV27dvLFF1/I2LFjZcKECfLuu+/W+jszZ86U2NjY6kmduQQAAAAA+HDxWFlZKVdccYXMmDHDOOv4wAMPyP333y9vvPFGrb+TlpYmeXl51VNmZqZX1xkAAAAAfJGti8dWrVrJpZdeWmNep06d5ODBg7X+TlhYmMTExNSYAAAAAAA+XDyqnlZ37dpVY95PP/0kSUlJlq0TAAAAAPgjWxePv//972X9+vXGZat79uyRRYsWyVtvvSXjxo2zetUAAAAAwK/Yunjs1auXLFu2TD744APp0qWLTJs2TWbPni0jR460etUAAAAAwK/YepxH5Ze//KUxAQAAAACsY+szjwAAAAAAe6B4BAAAAAA4/7LVn8vlchk/y8rKtI4/qVNJSYnWeMXFxaJbfn6+1nilpaVa4505c0ZrnKrPDbynapuXl5fb9nOmc908kfu6v+s88Zp1rxe56vw8tft7qPt7xBN5aue8r6iocMT77GuqtrfOY8Kq99Kux5a6jgWddBwREBCgJU7V58RMnga4fDybDx06JImJiVavBhwmMzNTEhISrF4Nv0KuoiHIVe8iT9FQ5Kp3kavwVJ76fPGozhIePnxYoqOj66zO1V8/VJGpNlpMTIw4Fa/j51HpcPr0aWndurUEBnJVtzeRq85k1XcOuWoN8tS5yFX/Qq46U74D9qk+f9mq2gD1OYOk3ignF49VeB0NFxsbq/GdgFnkqrNZ8Z1Drnofeep85Kp/IFedLcbG+1ROrQAAAAAA3KJ4BAAAAAC4RfH4X2FhYTJlyhTjp5PxOuDr+Izbi6+8H9DLVz4XvvI6fO21QB9f+VzwOrzH5zvMAQAAAAD8fJx5BAAAAAC4RfEIAAAAAHCL4hEAAAAA4BbFIwAAAADALb8qHl977TVJTk6W8PBw6dOnj2zYsKHO9h9++KF07NjRaH/ZZZfJP/7xD7HSzJkzpVevXhIdHS0tW7aUESNGyK5du+r8nQULFkhAQECNSb0eKz399NPnrZPazk56L+BZ5Cq5CvsjT+2Rpwr7VdSFXLVHrj7tI8e/flM8LlmyRCZNmmR0R7xp0ybp1q2bDB06VHJyci7Y/uuvv5a77rpL7r33Xtm8ebNRqKlp27ZtYpXVq1fLuHHjZP369fLPf/5TysrK5Prrr5fCwsI6fy8mJkaOHDlSPR04cECs1rlz5xrrtHbt2lrb2vG9gOeQq+Qq7I88tVeeKuxXcSHkqr1ytbMvHP+6/ETv3r1d48aNq35cUVHhat26tWvmzJkXbH/77be7hg8fXmNenz59XL/97W9ddpGTk6OGWXGtXr261jbz5893xcbGuuxkypQprm7duplu74T3AvqQq/ZBrqI25Km9kKuoDblqH1N85PjXL848lpaWysaNG2XIkCHV8wIDA43H69atu+DvqPlnt1fUmcra2lshLy/P+Nm0adM62xUUFEhSUpIkJibKzTffLNu3bxer7d69W1q3bi1t27aVkSNHysGDB2tt64T3AnqQq+Qq7I88tV+eKuxXcS5y1X65utsHjn/9ong8fvy4VFRUSFxcXI356nF2dvYFf0fNr097b6usrJSJEydK//79pUuXLrW269Chg8ybN0+WL18uf/3rX43f69evnxw6dEisou43Vfdirly5UubOnSsZGRly9dVXy+nTpx35XkAfcpVchf2Rp/bKU4X9Ki6EXLVXrvbxkePfYEuXjgZT9z6qa57rulZa6du3rzFVUYnTqVMnefPNN2XatGmWvAPDhg2r/n/Xrl2NZFJ/GVq6dKlxXTfgS8hVwP6cnKcK+1X4Cyfn6jAfOf71i+KxefPmEhQUJEePHq0xXz2Oj4+/4O+o+fVp703jx4+XTz/9VNasWSMJCQn1+t2QkBDp3r277NmzR+yicePG0r59+1rXyc7vBfQiV/8fchV2RZ7aO08V9qtQyFV752pjhx7/+sVlq6GhodKjRw9JT0+vnqdOX6vHZ/9V4mxq/tntFdXDaW3tvcHlchmF47Jly+Rf//qXpKSk1DuGunz3hx9+kFatWoldqHsy9+7dW+s62fG9gGeQq/8PuQq7Ik/tnacK+1Uo5Kq9c7XAqce/Lj+xePFiV1hYmGvBggWuHTt2uB544AFX48aNXdnZ2cbzv/nNb1x//OMfq9v/7//+rys4ONj14osvunbu3Gn0kBQSEuL64YcfLHsNY8eONXpOXbVqlevIkSPVU1FRUXWbc1/HM8884/riiy9ce/fudW3cuNF15513usLDw13bt2+36FW4XI888ojxGjIyMoztPGTIEFfz5s2N3mOd8l7Ac8hVchX2R57aJ08V9quoDblqn1x9xEeOf/2meFReeeUV10UXXeQKDQ01ui5ev3599XMDBgxwpaam1mi/dOlSV/v27Y32nTt3dn322WcuK6la/0KTGo6jttcxceLE6tccFxfnuuGGG1ybNm1yWemOO+5wtWrVylinNm3aGI/37NnjqPcCnkWukquwP/LUHnmqsF9FXchVe+TqHT5y/Bug/rH23CcAAAAAwO784p5HAAAAAMDPQ/EIAAAAAHCL4hEAAAAA4BbFIwAAAADALYpHAAAAAIBbFI8AAAAAALcoHgEAAAAAblE8AgAAAADcongEAAAAALhF8QgAAAAAcIviEQAAAADgFsUjAAAAAMAtikcAAAAAgFsUjwAAAAAAtygeAQAAAABuUTwCAAAAANyieAQAAAAAuEXxCAAAAABwi+LRD23atEluuukmadq0qURGRkqXLl1kzpw5Vq8WgLPs3r1b7rzzTklISDDytGPHjjJ16lQpKipiOwE2QZ4CzkCu6hOsMRYc4Msvv5Qbb7xRunfvLpMnT5aoqCjZu3evHDp0yOpVA/BfmZmZ0rt3b4mNjZXx48cbf+hZt26dTJkyRTZu3CjLly9nWwEWI08BZyBX9aJ49CP5+fkyatQoGT58uHz00UcSGMiJZ8CO3nvvPcnNzZW1a9dK586djXkPPPCAVFZWysKFC+XUqVPSpEkTq1cT8GvkKeAM5KpeVA9+ZNGiRXL06FGZPn26UTgWFhYaB6MA7PeHHiUuLq7G/FatWhm5GxoaatGaAahCngLOQK7qRfHoR7766iuJiYmRrKws6dChg3HJqno8duxYKS4utnr1APzXwIEDjZ/33nuvbNmyxbjkZsmSJTJ37lyZMGGCNGrUiG0FWIw8BZyBXNUrwOVyuTTHhE1169ZN9uzZU31QqpJp1apV8sorrxgdc3zwwQdWryKA/3r22WdlxowZcubMmept8uSTTxrzAdgDeQo4A7mqD/c8+pGCggKjp8YHH3ywunfVW265RUpLS+XNN980enJs166d1asJQESSk5PlmmuukVtvvVWaNWsmn332mVFMxsfHG53oALAeeQo4A7mqD2ce/YgakmP79u2yevVq46C0ypo1a2TAgAHy7rvvGh3qALDW4sWLZcyYMfLTTz8ZQ3VUGT16tCxdulQOHjxoFJQArEOeAs5ArurFPY9+pHXr1hfshKNly5bGT9WDIwDrvf7668ZwOmcXjooan1VdPbB582bL1g3A/yFPAWcgV/WiePQjPXr0MH6qDnPOdvjwYeNnixYtLFkvADWpXpErKirO2yxlZWXGz/LycjYZYDHyFHAGclUvikc/cvvttxs/33nnnRrz//KXv0hwcHB1b1QArNW+fXvj7KK6bPVsqlMrNVRH165dLVs3AP+HPAWcgVzViw5z/Ii6DE7dRzVv3jzjzIW6z1H1tvrhhx9KWlpa9WWtAKz16KOPyueffy5XX3210TmOur/x008/Nebdd9995CpgA+Qp4Azkql50mONn1GVvqsfG+fPnG5erJiUlybhx42TixIlWrxqAs2zYsEGefvpp4wzkiRMnJCUlRVJTU+Wxxx4zrhQAYD3yFHAGclUfikcAAAAAgFvc8wgAAAAAcIviEQAAAADgFsUjAAAAAMAtikcAAAAAgFsUjwAAAAAAtygeAQAAAABu+fxgYZWVlcZ4htHR0RIQEGD16sDmXC6XnD592hiEPTCQv614E7mK+iBXrUGeor7IVWuQq/BUnvp88agKx8TERKtXAw6TmZkpCQkJVq+GXyFX0RDkqneRp2goctW7yFV4Kk99vnhUZxyVsLAwbWceU1JSRKeuXbtqjbd161bR7ZJLLtEa7x//+IfWeBdddJG2v9QdPHiw+nMD76na5qNHj5bQ0FAtMRctWiQ6Pfvss1rjJSUliW4ZGRla43377bda4/3ud7/TEqewsFCGDh1KrlqUpwsXLpTIyEgtMX/961+LTlOnTtUar127dqLbDTfcIHb2wgsvaItVUlIiL774IrlqUa4OGzZMQkJCtMTMysoSnXR9h1S57rrrRDfd65iXl6c1njpm1aG0tFQ++OADU3nq88VjVcGofuoqHoOCgkQnXQfKnlo/RdcXTxXdlxDrvsSUS5y9r2qbq3zQlRO638eIiAit8Ro1aiS66V5H3d9PUVFRWuORq95Vtb3VAZUnPr86hIeH2/rgUYmJiRE7070NFXLVu6q2tzp+03UMp/v4Mjg42PafW9371JKSElvvo83kKTd1AQAAAADcongEAAAAALhF8QgAAAAA8I3i8bXXXpPk5GTjWuY+ffrIhg0brF4lAAAAAPArti8elyxZIpMmTZIpU6bIpk2bpFu3bkYPezk5OVavGgAAAAD4DdsXjy+99JLcf//9Rvf9l156qbzxxhtGz2fz5s2zetUAAAAAwG/YunhUY45s3LhRhgwZUmNIBvV43bp1tXaBm5+fX2MCAAAAAPhw8Xj8+HGpqKiQuLi4GvPV4+zs7Av+zsyZMyU2NrZ6SkxM9NLaAgAAAIDvsnXx2BBpaWmSl5dXPWVmZlq9SgAAAADgeMFiY82bN5egoCA5evRojfnqcXx8/AV/JywszJgAAAAAAH5y5jE0NFR69Ogh6enp1fMqKyuNx3379rV03QAAAADAn9j6zKOihulITU2Vnj17Su/evWX27NlSWFho9L4KAAAAAPAO2xePd9xxhxw7dkyeeuopo5Ocyy+/XFauXHleJzoAAAAAAD8uHpXx48cbEwAAAADAGra+5xEAAAAAYA8UjwAAAAAA37hsVYfi4mJtsQoKCkSnNWvWaI2nOhTSTd13qpPqNVennJwcLXFcLpeWOGi4Xbt2SXCwnq+mM2fOaH0rnnnmGa3xQkJCRLdDhw5pjTdixAit8bp166YlTn5+vpY4aJhWrVpJVFSUrT4TVWJiYrTGi42NFd2io6Ntvd9nX+g7vvzySwkICNASq6ysTHTq37+/7XO1qKhIa7y8vDxbxqvPe8uZRwAAAACAWxSPAAAAAAC3KB4BAAAAAN6753HFihX1/p3rrrtOIiIidK0CAAAAAMDuxWN9O1VQN+/u3r1b2rZtq2sVAAAAAABOuGw1Ozvb6EXTzBQZGalz0QAAAAAAJxSPqamp9boE9e6779benTYAAAAAwOaXrc6fP79e7efOnatr0QAAAAAAD6O3VQAAAACA94vHrVu3yrPPPiuvv/66HD9+vMZz+fn5MmbMGN2LBAAAAAA4qXj88ssvpXfv3rJ48WJ5/vnnpWPHjvLvf/+7+vkzZ87Iu+++q3ORAAAAAACnFY9PP/20/OEPf5Bt27bJ/v375bHHHpObbrpJVq5cqXMxAAAAAACndpijbN++Xd57773qcRxV8ZiQkCC//vWvjbORvXr10rk4AAAAAIATi8ewsDDJzc2tMe9//ud/JDAwUO644w6ZNWuWzsUBAAAAAJxYPF5++eXGPY49evSoMf/OO+8Ul8tljAUJAAAAAPDz4nHs2LGyZs2aCz531113GQXk22+/rXORAAAAAACnFY+/+tWvjKk26hJWNQEAAAAA/HycRwAAAACA76F4BAAAAAB497JVO4uKijKGD9Hh6NGjolP37t21xvv+++9Ft5CQEK3xmjRpojWerve2srJSCgsLtcRCw4f8UT0061BWVqb1bVCfD5088VkLDQ3VGk+N2auT6lRNB/LUWl26dJGYmBgtsdauXSs6jRo1Smu8G2+8UXRbsmSJ1nhTpkzRGi8zM1Pr9+axY8e0xUP9JCcnS1BQkJbN9uGHH2rd/Hl5eVrj9e3bV3RLSkrSXo/oVFBQ4PXjG848AgAAAADcongEAAAAANireFy+fLksXLjQm4sEAAAAADiteHz88cdl9OjR3lwkAAAAAMBpHeb8+OOP3lwcAAAAAEAT7nkEAAAAAFh35jE3N1c2bNggOTk553X/arYb7ZkzZ8rf/vY344xlRESE9OvXT55//nnp0KGDh9YaAAAAAOC14vHvf/+7jBw50hh7RI0DdfYYfOr/ZovH1atXy7hx46RXr15SXl4uTzzxhFx//fWyY8cOadSokSdWHQAAAADgreLxkUcekTFjxsiMGTMkMjKywXFWrlxZ4/GCBQukZcuWsnHjRrnmmms0rCkAAAAAwLLiMSsrSyZMmPCzCscLycvLM342bdq01jYlJSXGVCU/P1/rOgAAAACAP/JIhzlDhw6V7777TmtMdd/kxIkTpX///tKlS5c675OMjY2tnhITE7WuBwAAAAD4I21nHlesWFH9/+HDh8ujjz5q3Jt42WWXSUhISI22N910U73jq3sft23bJmvXrq2zXVpamkyaNKnGmUcKSAAAAACwSfE4YsSI8+ZNnTr1vHmqw5yKiop6xR4/frx8+umnsmbNGklISKizbVhYmDEBAAAAAGxYPJ47HIcOLpdLHnroIVm2bJmsWrVKUlJStC8DAAAAAGDhOI86qEtVFy1aJMuXL5fo6GjJzs425qt7GdW4jwAAAAAAB3eYo3panTNnznnzX331VaPTG7Pmzp1r9LA6cOBAadWqVfW0ZMkSzWsMAAAAAPB68fjxxx8bvaKeq1+/fvLRRx/V67LVC0333HOP5jUGAAAAAHi9eDxx4oRxaem5YmJi5Pjx455YJAAAAADAacXjJZdcIitXrjxv/ueffy5t27b1xCIBAAAAAE7rMEeNs6iG1zh27JgMGjTImJeeni6zZs2S2bNnixXUWJNqmBAdSktLRaecnByt8QoLC0W3wEC9f2c4d+zPn6tLly5a4qhhZE6dOqUlFhpGfW/oylXdnzPdudW1a1fRraCgQGu8jIwMrfHUOMA6qFsY4BuioqK0xrv66qu1xrvQH8Pttk/V/ZrVFWS6qGOmxYsXa4uH+jlw4IC2farqd0SnTp06aY2Xm5srutV3eEF3srKyRKdevXp5fZ/qkeJxzJgxUlJSItOnT5dp06YZ85KTk40OcEaNGuWJRQIAAAAAnDhUx9ixY41JnUVQw2ro/ssiAAAAAMCHxnls0aKFpxcBAAAAAPAwbRfdX3HFFfW6V+yqq67Sft0vAAAAAMDmZx63bNkiW7dulaZNm5pur+6LBAAAAAD42WWrgwcPNt1bj66enwAAAAAADioeG9Kde0JCgq7FAwAAAACcUDwmJSXpCgUAAAAAsBm9o9QCAAAAAHwSxSMAAAAAwC2KRwAAAACAWxSPAAAAAABrise2bdvKiRMnzpufm5trPAcAAAAAcBaPFI/79++XioqK8+aXlJRIVlaWJxYJAAAAAHDCUB3KihUrqv//xRdfSGxsbPVjVUymp6dLcnKyzkUCAAAAAJxWPI4YMcL4GRAQIKmpqTWeCwkJMQrHWbNm6VwkAAAAAMBpxWNlZaXxMyUlRb799ltp3ry5zvAAAAAAAF8oHqtkZGR4IiwAAAAAwJeKx6lTp9b5/FNPPeWJxQIAAAAAnFQ8Llu2rMbjsrIy42xkcHCwXHzxxRSPAAAAAOAwHikeN2/efN68/Px8ueeee+RXv/qVWKF9+/ZG8arDzp07RffQJjqpzol0u9DQKz9HfHy81ni6evFVf+i40OcX3nPJJZdIUFCQLS+hLy4u1hpP93eJMn/+fK3xysvLtca77bbbtMRxuVxa4sD3VHXep8vSpUtFN919Qlx55ZVa46l+K3RRw7TBOurYV3VkqcMvf/lL0WnNmjVa40VGRopu6rhQp2HDhmmNd/bIFj+335rjx49bN87jhcTExMgzzzwjkydP9tYiAQAAAACaeK14VPLy8owJAAAAAOAsHrlsdc6cOeddXnTkyBF57733tJ+uBQAAAAA4tHh8+eWXazwODAyUFi1aSGpqqqSlpXlikQAAAAAAD2KcRwAAAACA9fc8ZmZmGpMOzz33nNFj1MSJE7XEAwAAAABYWDyqrt1Vr6qq+1g1hIKa1P//9Kc/NbjLW9Vt9Jtvvildu3bVvr4AAAAAAAuKx4ceekjeeusteeGFF4wx89Sk/v/OO+/IhAkT6h2voKBARo4cKW+//bY0adLEE6sMAAAAAPD2PY+LFi2SxYsX1+hZVZ0xTExMlLvuukvmzp1br3jjxo2T4cOHy5AhQ+TZZ591Oxjt2QPS5ufnN+AVAAAAAAA8XjyGhYUZl6qeKyUlRUJDQ+sVSxWhmzZtMi5bNWPmzJnyzDPP1GsZAAAAAAALLlsdP368TJs2rcYZQPX/6dOnG8+ZpTraefjhh+X999+X8PBwU7+jhgLJy8urnnR11gMAAAAA/swjZx7VPY7p6emSkJAg3bp1M+Zt3bpVSktLZfDgwXLLLbdUt/3b3/5Wa5yNGzdKTk6OXHHFFdXzKioqZM2aNfLqq68aBWlQUNB5Zz3VBAAAAACwefHYuHFjufXWW2vMU/c71pcqNH/44Yca80aPHi0dO3aUxx9//LzCEQAAAADgoOJx/vz5WuJER0dLly5dasxr1KiRNGvW7Lz5AAAAAACH3fM4aNAgyc3NPW++6vlUPQcAAAAAcBaPnHlctWqVcX/juYqLi+U///nPz44NAAAAAHBw8fj9999X/3/Hjh2SnZ1do6OblStXSps2bXQuEgAAAADgtOLx8ssvl4CAAGO60OWpERER8sorr+hcJAAAAADAacVjRkaGuFwuadu2rWzYsEFatGhR/VxoaKi0bNmSHlIBAAAAwN+Lx6SkJONnZWWl2M3AgQO1jf8YHx8vOu3du1drvIMHD4pu/fv31xrv3nvv1RovMjJSS5zCwkJZvny5llhomDNnzkhgYKAtc1X3d1t4eLjoNnLkSK3x1C0Hdo4HnOuiiy7SulG+/vpr7Rv5hhtu0BovJSVF7KqoqMjqVfBrZWVlxhWBOuzcuVN0Cg7W2/XKww8/LLp98sknWuMdP35cazx10s7bcTzSYc7ChQvrfH7UqFGeWCwAAAAAwEM8UjyeW/mrv3qovzypS1fVGSKKRwAAAABwFo+M83jq1KkaU0FBgezatUuuuuoq+eCDDzyxSAAAAACA04rHC2nXrp0899xzHrkeGQAAAADgI8Vj1Y2xhw8f9uYiAQAAAAB2vedxxYoV5/Xgc+TIEXn11Ve199oJAAAAAHBo8ThixIgaj1UXwWrMx0GDBsmsWbM8sUgAAAAAgNOKRzuO8wgAAAAAsOk9j2ogTN2DYQIAAAAAfKB4zM3NlXHjxknz5s0lLi7OmNT/x48fbzwHAAAAAPDzy1ZPnjwpffv2laysLBk5cqR06tTJmL9jxw5ZsGCBpKeny9dffy1NmjTRuVgAAAAAgJOKx6lTp0poaKjs3bvXOON47nPXX3+98fPll1/WuVgAAAAAgJMuW/3kk0/kxRdfPK9wVOLj4+WFF16QZcuW6VwkAAAAAMBpxaMay7Fz5861Pt+lSxfJzs7WuUgAAAAAgNOKR9Uxzv79+2t9PiMjQ5o2bapzkQAAAAAApxWPQ4cOlSeffFJKS0vPe66kpEQmT54sv/jFL3QuEgAAAADgxA5zevbsKe3atTOG6+jYsaO4XC7ZuXOnvP7660YB+d577+lcJAAAAADAacVjQkKCrFu3Tn73u99JWlqaUTgqAQEBct1118mrr74qiYmJOhcJAAAAAHBa8aikpKTI559/LqdOnZLdu3cb8y655BLudQQAAAAAB9NePFZp0qSJ9O7dW+xC3WsZFRWlJVazZs1E9xlbnVThrlv//v21xouOjtYab9CgQVri5Ofna4mDhuvbt6+EhIRo2YQ//PCD1rdi165dWuO1aNFCdLvhhhtsnasff/yxljjqypbc3FwtsWCtyspKrfHOnDmjNd6OHTtEt1//+tda45WVlWmNl5mZqS1WcXGxtliov4qKCuMKQB0KCgq0vgWDBw/WGu/AgQOim+5jatd/r8rUJTAw0OvrpbXDHAAAAACAb6J4BAAAAAC4RfEIAAAAAHCL4hEAAAAA4BbFIwAAAADA+cVjVlaW3H333UYPpxEREXLZZZfJd999Z/VqAQAAAIBf8dhQHbq6x1VDRFx77bXG2JGqW3s1dqQaBgQAAAAA4D22Lh6ff/55SUxMlPnz51fPS0lJsXSdAAAAAMAf2fqy1RUrVkjPnj3ltttuk5YtW0r37t3l7bffrvN3SkpKjIHez54AAAAAAD5cPO7bt0/mzp0r7dq1ky+++ELGjh0rEyZMkHfffbfW35k5c6bExsZWT+rMJQAAAADAh4vHyspKueKKK2TGjBnGWccHHnhA7r//fnnjjTdq/Z20tDTJy8urnjIzM726zgAAAADgi2xdPLZq1UouvfTSGvM6deokBw8erPV3wsLCJCYmpsYEAAAAAPDh4lH1tLpr164a83766SdJSkqybJ0AAAAAwB/Zunj8/e9/L+vXrzcuW92zZ48sWrRI3nrrLRk3bpzVqwYAAAAAfsXWxWOvXr1k2bJl8sEHH0iXLl1k2rRpMnv2bBk5cqTVqwYAAAAAfsXW4zwqv/zlL40JAAAAAGAdW595BAAAAADYA8UjAAAAAMD5l63+XC6Xy/hZWFioLWZxcbHoVFJSojVeaWmp6HbmzBmt8XS+H0p+fr7WOFWfG3hP1TYvKyvTFrOiokJ00v25UGPZ6qZz+3ni+0TXNqyKQ656V9X21vWd64k8KCoqsn2e2n2fqvM4pyoWuepdTviOLC8vt/X+zxPbz2XTePX5vAS47Pyp0uDQoUOSmJho9WrAYTIzMyUhIcHq1fAr5Coaglz1LvIUDUWuehe5Ck/lqc8Xj+ovhocPH5bo6GgJCAiotZ36K6oqMtVGi4mJEafidfw8Kh1Onz4trVu3lsBArur2JnLVmaz6ziFXrUGeOhe56l/IVWfKd8A+1ecvW1UboD5nkNQb5eTisQqvo+FiY2M1vhMwi1x1Niu+c8hV7yNPnY9c9Q/kqrPF2HifyqkVAAAAAIBbFI8AAAAAALcoHv8rLCxMpkyZYvx0Ml4HfB2fcXvxlfcDevnK58JXXoevvRbo4yufC16H9/h8hzkAAAAAgJ+PM48AAAAAALcoHgEAAAAAblE8AgAAAADcongEAAAAALjlV8Xja6+9JsnJyRIeHi59+vSRDRs21Nn+ww8/lI4dOxrtL7vsMvnHP/4hVpo5c6b06tVLoqOjpWXLljJixAjZtWtXnb+zYMECCQgIqDGp12Olp59++rx1UtvZSe8FPItcJVdhf+SpPfJUYb+KupCr9sjVp33k+NdvisclS5bIpEmTjO6IN23aJN26dZOhQ4dKTk7OBdt//fXXctddd8m9994rmzdvNgo1NW3btk2ssnr1ahk3bpysX79e/vnPf0pZWZlcf/31UlhYWOfvxcTEyJEjR6qnAwcOiNU6d+5cY53Wrl1ba1s7vhfwHHKVXIX9kaf2ylOF/SouhFy1V6529oXjX5ef6N27t2vcuHHVjysqKlytW7d2zZw584Ltb7/9dtfw4cNrzOvTp4/rt7/9rcsucnJy1DArrtWrV9faZv78+a7Y2FiXnUyZMsXVrVs30+2d8F5AH3LVPshV1IY8tRdyFbUhV+1jio8c//rFmcfS0lLZuHGjDBkypHpeYGCg8XjdunUX/B01/+z2ijpTWVt7K+Tl5Rk/mzZtWme7goICSUpKksTERLn55ptl+/btYrXdu3dL69atpW3btjJy5Eg5ePBgrW2d8F5AD3KVXIX9kaf2y1OF/SrORa7aL1d3+8Dxr18Uj8ePH5eKigqJi4urMV89zs7OvuDvqPn1ae9tlZWVMnHiROnfv7906dKl1nYdOnSQefPmyfLly+Wvf/2r8Xv9+vWTQ4cOiVXU/abqXsyVK1fK3LlzJSMjQ66++mo5ffq0I98L6EOukquwP/LUXnmqsF/FhZCr9srVPj5y/Bts6dLRYOreR3XNc13XSit9+/Y1pioqcTp16iRvvvmmTJs2zZJ3YNiwYdX/79q1q5FM6i9DS5cuNa7rBnwJuQrYn5PzVGG/Cn/h5Fwd5iPHv35RPDZv3lyCgoLk6NGjNearx/Hx8Rf8HTW/Pu29afz48fLpp5/KmjVrJCEhoV6/GxISIt27d5c9e/aIXTRu3Fjat29f6zrZ+b2AXuTq/0Ouwq7IU3vnqcJ+FQq5au9cbezQ41+/uGw1NDRUevToIenp6dXz1Olr9fjsv0qcTc0/u72iejitrb03uFwuo3BctmyZ/Otf/5KUlJR6x1CX7/7www/SqlUrsQt1T+bevXtrXSc7vhfwDHL1/yFXYVfkqb3zVGG/CoVctXeuFjj1+NflJxYvXuwKCwtzLViwwLVjxw7XAw884GrcuLErOzvbeP43v/mN649//GN1+//93/91BQcHu1588UXXzp07jR6SQkJCXD/88INlr2Hs2LFGz6mrVq1yHTlypHoqKiqqbnPu63jmmWdcX3zxhWvv3r2ujRs3uu68805XeHi4a/v27Ra9CpfrkUceMV5DRkaGsZ2HDBniat68udF7rFPeC3gOuUquwv7IU/vkqcJ+FbUhV+2Tq4/4yPGv3xSPyiuvvOK66KKLXKGhoUbXxevXr69+bsCAAa7U1NQa7ZcuXepq37690b5z586uzz77zGUlVetfaFLDcdT2OiZOnFj9muPi4lw33HCDa9OmTS4r3XHHHa5WrVoZ69SmTRvj8Z49exz1XsCzyFVyFfZHntojTxX2q6gLuWqPXL3DR45/A9Q/1p77BAAAAADYnV/c8wgAAAAA+HkoHgEAAAAAblE8AgAAAADcongEAAAAALhF8QgAAAAAcIviEQAAAADgFsUjAAAAAMAtikcAAAAAgFsUjwAAAAAAtygeAQAAAABuUTwCAAAAANyieAQAAAAAuEXxCAAAAABwi+IRAAAAAOAWxSMAAAAAwC2KRwAAAACAWxSPAAAAAAC3KB4BAAAAAG5RPPqhTZs2yU033SRNmzaVyMhI6dKli8yZM8fq1QJwlt27d8udd94pCQkJRp527NhRpk6dKkVFRWwnwCbIU8AZyFV9gjXGggN8+eWXcuONN0r37t1l8uTJEhUVJXv37pVDhw5ZvWoA/iszM1N69+4tsbGxMn78eOMPPevWrZMpU6bIxo0bZfny5WwrwGLkKeAM5KpeFI9+JD8/X0aNGiXDhw+Xjz76SAIDOfEM2NF7770nubm5snbtWuncubMx74EHHpDKykpZuHChnDp1Spo0aWL1agJ+jTwFnIFc1YvqwY8sWrRIjh49KtOnTzcKx8LCQuNgFID9/tCjxMXF1ZjfqlUrI3dDQ0MtWjMAVchTwBnIVb0oHv3IV199JTExMZKVlSUdOnQwLllVj8eOHSvFxcVWrx6A/xo4cKDx895775UtW7YYl9wsWbJE5s6dKxMmTJBGjRqxrQCLkaeAM5CregW4XC6X5piwqW7dusmePXuqD0pVMq1atUpeeeUVo2OODz74wOpVBPBfzz77rMyYMUPOnDlTvU2efPJJYz4AeyBPAWcgV/Xhnkc/UlBQYPTU+OCDD1b3rnrLLbdIaWmpvPnmm0ZPju3atbN6NQGISHJyslxzzTVy6623SrNmzeSzzz4zisn4+HijEx0A1iNPAWcgV/XhzKMfUUNybN++XVavXm0clFZZs2aNDBgwQN59912jQx0A1lq8eLGMGTNGfvrpJ2OojiqjR4+WpUuXysGDB42CEoB1yFPAGchVvbjn0Y+0bt36gp1wtGzZ0vipenAEYL3XX3/dGE7n7MJRUeOzqqsHNm/ebNm6Afg/5CngDOSqXhSPfqRHjx7GT9VhztkOHz5s/GzRooUl6wWgJtUrckVFxXmbpayszPhZXl7OJgMsRp4CzkCu6kXx6Eduv/124+c777xTY/5f/vIXCQ4Oru6NCoC12rdvb5xdVJetnk11aqWG6ujatatl6wbg/5CngDOQq3rRYY4fUZfBqfuo5s2bZ5y5UPc5qt5WP/zwQ0lLS6u+rBWAtR599FH5/PPP5eqrrzY6x1H3N3766afGvPvuu49cBWyAPAWcgVzViw5z/Iy67E312Dh//nzjctWkpCQZN26cTJw40epVA3CWDRs2yNNPP22cgTxx4oSkpKRIamqqPPbYY8aVAgCsR54CzkCu6kPxCAAAAABwi3seAQAAAABuUTwCAAAAANyieAQAAAAAuEXxCAAAAABwi+IRAAAAAOAWxSMAAAAAwC2fHyyssrLSGM8wOjpaAgICrF4d2JzL5ZLTp08bg7AHBvK3FW8iV1Ef5Ko1yFPUF7lqDXIVnspTny8eVeGYmJho9WrAYTIzMyUhIcHq1fAr5Coaglz1LvIUDUWuehe5Ck/lqc8Xj+qMo6KqaF1nHtu0aSM6tWrVSmu8Xbt2iW6NGjXSGi87O1trvBYtWmj7S11OTk715wbeU7XN+/fvL8HBer6atm7dKjo98cQTWuN16NBBdHv88cdtvY6zZ8/WEkf9hbRr167kqkV5mpycrO3qDHWQq1OnTp20xhs7dqzodscdd2iNt2XLFq3xBgwYILqxX/Wuqu3dvXt3CQoK0hJz7969YudjS3X8oJvuqxaPHz+uNV5WVpaWOBUVFfLTTz+ZylOfLx6r3nT1U9cHQPfljLoOlKt44vJc3a9Z9zraff1gfpurfNCVE7rfx4iICFvvOBVdBwlVQkJCtMaLiYnRGo9c9a6q7a2+c3V97+p+D3XngO6890QeREVFid2Rq9Zsb5UPdt2n6j52Cw0NFd10v+Zgzcf8ur/vzLxebuoCAAAAALhF8QgAAAAAcIviEQAAAADgG8Xja6+9ZtycHx4eLn369JENGzZYvUoALoBcBZyBXAXsjzyFHdm+eFyyZIlMmjRJpkyZIps2bZJu3brJ0KFDjR4xAdgHuQo4A7kK2B95CruyffH40ksvyf333y+jR4+WSy+9VN544w2JjIyUefPmWb1qAM5CrgLOQK4C9keewq5sXTyWlpbKxo0bZciQITW69VWP161bd8HfKSkpkfz8/BoTAHIVQP33q+xTAe/j+Bd2ZuviUQ2kqQatjIuLqzFfPa5tkPmZM2dKbGxs9ZSYmOiltQX8F7kK+Gausk8FvI99KuzM1sVjQ6SlpUleXl71lJmZafUqAbgAchWwP/IUcAZyFd4SLDbWvHlzCQoKkqNHj9aYrx7Hx8df8HfCwsKMCYD3kKuAb+Yq+1TA+9inws5sfeYxNDRUevToIenp6dXzKisrjcd9+/a1dN0A/D/kKuAM5Cpgf+Qp7MzWZx4VNUxHamqq9OzZU3r37i2zZ8+WwsJCo/dVAPZBrgLOQK4C9keewq5sXzzecccdcuzYMXnqqaeMm/kvv/xyWbly5Xk3+wOwFrkKOAO5CtgfeQq7sn3xqIwfP96YANgbuQo4A7kK2B95Cjuy9T2PAAAAAAB7oHgEAAAAAPjGZas6qEGRdVEd9ui0YcMGrfECA/X/TaCkpERrvPLycq3xTp06pSWOy+XSEgcNd/jwYWMoAR0KCgq0vhVPPPGE9h71dCsqKtIab9iwYVrjNW3aVEuc4GC/2X3ZkhrCQ1eeXnzxxaLTL37xC63xnn/+edFt4sSJts778PBwbbHUflX3MQTM++6772y7uVq3bq01nif2C7qPI86cOWPL9VOjWZjFmUcAAAAAAMUjAAAAAODn48wjAAAAAMAtikcAAAAAgFva7ixdsWJFvX/nuuuuk4iICF2rAAAAAACwe/E4YsSIerUPCAiQ3bt3S9u2bXWtAgAAAADACZetZmdnG129mpkiIyN1LhoAAAAA4ITiMTU1tV6XoN59990SExOja/EAAAAAACdctjp//vx6tZ87d66uRQMAAAAAPIzeVgEAAAAA3i8e//KXvxiXsFadiVyyZIl06tTJ6BhnypQpvCUAAAAA4M+XrSqzZ8+WP/3pTzJ06FB58skn5fDhw/Lyyy/L73//e6moqJBZs2ZJmzZt5IEHHtC5WAAAAACAk4rHN998U9566y35n//5H9m8ebP07t1b3njjDbn33nuN51XhqO51pHgEAAAAAD++bPXAgQNy1VVXGf/v3r27BAUFyZVXXln9/IABA2Tv3r06FwkAAAAAcFrxqMZuLCwsrH7cokULiYqKqtGmvLxc5yIBAAAAAE4rHjt27Cjff/999ePMzExJSkqqfvzjjz9KcnKyzkUCAAAAAJx2z+Pzzz8vjRo1qvX5gwcPym9/+1udiwQAAAAAOK147N+/f53P/+53v9O5OAAAAACAU8d5BAAAAAD4Hq1nHu0sMDBQAgICtMQ6c+aM6BQfH681nrrXVLdmzZppjVdUVKQ1XlhYmJY4LpdLiouLtcRCw6jtr/JVB90ddEVERGiNd/r0adFN17arsnXrVq3xdOUXeWqt9evXS0xMjJZYCQkJotOGDRu0xlNDjOn20ksvaY33n//8R2u8srIybbHUfrWkpERbPNRPSkqKtv2CGrtdJzX+u07z588X3XR9z1UpLS0VndTIFrry1CzOPAIAAAAA3KJ4BAAAAAC4RfEIAAAAALBX8bh8+XJZuHChNxcJAAAAAHBa8fj444/L6NGjvblIAAAAAIDTelv98ccfvbk4AAAAAIA/3PM4c+ZM6dWrl0RHR0vLli1lxIgRsmvXLqtXC8A5yFXAGchVwBnIVfjdmcfc3FxjrKWcnByprKys8dyoUaNMxVi9erWMGzfOKCDVeG1PPPGEXH/99bJjxw5p1KiRh9YcQH2Rq4AzkKuAM5Cr8Kvi8e9//7uMHDlSCgoKjME1AwICqp9T/zdbPK5cubLG4wULFhhnIDdu3CjXXHON9vUG0DDkKuAM5CrgDOQq/Kp4fOSRR2TMmDEyY8YMiYyM1BY3Ly/P+Nm0adNa25SUlBhTlfz8fG3LB2AOuQr4Rq6yTwXsgVyFT9/zmJWVJRMmTNBaOKpLXydOnCj9+/eXLl261HmNeGxsbPWUmJiobR0AuEeuAr6Tq+xTAeuRq/D54nHo0KHy3XffaY2p7n3ctm2bLF68uM52aWlpxl9nqqbMzEyt6wGgbuQq4Du5yj4VsB65Cp+8bHXFihXV/x8+fLg8+uijRsc2l112mYSEhNRoe9NNN9Ur9vjx4+XTTz+VNWvWSEJCQp1tw8LCjAmA95GrgG/lKvtUwFrkKny2eFTDaJxr6tSp581THeZUVFSYiulyueShhx6SZcuWyapVqyQlJUXLugLQi1wFnIFcBZyBXIXPF4/nDseh6zT9okWLZPny5cZYj9nZ2cZ8dS9jRESE9uUBaBhyFXAGchVwBnIVfnXPoy5z58417lscOHCgtGrVqnpasmSJ1asG4CzkKuAM5CrgDOQq/GqoDtXT6iWXXGL8PNurr74qe/bskdmzZ5s+ZQ/A/shVwBnIVcAZyFX41ZnHjz/+2Oj6+1z9+vWTjz76yBOLBAAAAAA4rXg8ceKEcV/iuWJiYuT48eOeWCQAAAAAwGmXrapLVleuXGl0L3y2zz//XNq2bStWUL28qkmHsrIy0enUqVNa4+l6nWfLzc3VGi84WO9HLz4+Xksc1ROwus8W1snKytL2GdY9bE9+fr7WeLfddpvopvvqjl27dmmNFxkZqSUOl3T5jkOHDmmN16lTJ63xVKd9uoWHh2uN1759e63xjh49Kjo7VNT93Qnz9u/fr22fev3112vd9Ndee63WePv27RPddHcI+uWXX2qNN3nyZK/vUz1SPE6aNMkoHI8dOyaDBg0y5qWnp8usWbNM3+8IAAAAALAPjxSPY8aMkZKSEpk+fbpMmzbNmJecnGz0HDVq1ChPLBIAAAAA4LTiURk7dqwxqbOPakzGqKgoTy0KAAAAAODU4rFKixYtPL0IAAAAAIBTelu94oor6tXxy1VXXWV0jAEAAAAA8KMzj1u2bJGtW7dK06ZNTbdX90UCAAAAAPzsstXBgweb7urVE8NJAAAAAABsXjxmZGTU+3cSEhJ0LR4AAAAA4ITiMSkpSVcoAAAAAICvdpgDAAAAAPBdFI8AAAAAALcoHgEAAAAAblE8AgAAAACsKR7btm0rJ06cOG9+bm6u8RwAAAAAwFk8Ujzu379fKioqzptfUlIiWVlZnlgkAAAAAMAJQ3UoK1asqP7/F198IbGxsdWPVTGZnp4uycnJOhcJAAAAAHBa8ThixAjjZ0BAgKSmptZ4LiQkxCgcZ82apXORAAAAAACnFY+VlZXGz5SUFPn222+lefPmOsMDAAAAAHyheKySkZHhibAAAAAAAF8qHqdOnVrn80899ZQnFgsAAAAAcFLxuGzZshqPy8rKjLORwcHBcvHFF1tSPDZr1kwCA/V0Lnvs2DHRqby8XGs8dc+p3an3w47xdL8XaPjl73aLpYSHh2uN9/e//110W7p0qdZ4K1eu1BrvjTfe0BLH5XJpf3/hG1SP7zr99NNPopvuYctatGihNd7XX3+tLdaFet+H96g+R3QdF/bp00d02rJli9Z46rY53Q4fPqw13tNPP601ntoXejuOR4rHzZs3nzcvPz9f7rnnHvnVr37liUUCAAAAAJw2zuOFxMTEyDPPPCOTJ0/21iIBAAAAAE4rHpW8vDxjAgAAAAA4i0cuW50zZ85519EeOXJE3nvvPRk2bJgnFgkAAAAAcFrx+PLLL9d4rDqqUTdzp6amSlpamicWCQAAAABw2mWrqmfVs6e9e/fK+vXrZcaMGRIdHd3guM8995zRY9TEiRO1ri8AvchVwBnIVcD+yFP41T2PmZmZxvRzffvtt/Lmm29K165dtawXAM8gVwFnIFcB+yNP4RfFoxorT/WqGhsbK8nJycak/v+nP/3JGPOxvgoKCmTkyJHy9ttvS5MmTTyxygA0IFcBZyBXAfsjT+E3xeNDDz0kb731lrzwwgvGmI9qUv9/5513ZMKECfWON27cOBk+fLgMGTLEbduSkhJjTMmzJwDeQa4CvpWr7FMB67BPhd90mLNo0SJZvHhxjZ5V1eWmiYmJctddd8ncuXNNx1JxNm3aZJy2N2PmzJnGeJIAvItcBXwvV9mnAtZgnwq/OvMYFhZmXKp6rpSUFAkNDTUdR90r+fDDD8v7778v4eHhpn5H9eZaNZ6kmnTcbwmgbuQq4Ju5yj4V8D72qfC7M4/jx4+XadOmyfz5841CsurSl+nTpxvPmbVx40bJycmRK664onpeRUWFrFmzRl599VUjZlBQUI3fUcurWiYA7yBXAd/MVfapgP3zVCFX4ejiUd3jmJ6eLgkJCdKtWzdj3tatW6W0tFQGDx4st9xyS3Xbv/3tb7XGUW1/+OGHGvNGjx4tHTt2lMcff/y8xAFgDXIVcAZyFbA/8hR+Vzw2btxYbr311hrz1P2O9aXGhOzSpUuNeY0aNZJmzZqdNx+AdchVwBnIVcD+yFP4XfGoLlcFAAAAAPgOjxSPgwYNMi5HVWcgz6aGzRgxYoT861//anDsVatWaVhDAJ5GrgLOQK7i/2/vzmOjKP84jn8XoS0m9MDS0tJaIBYpLWAVaLAYI0EOj8g/iqYeiUYMlijKH0qMKUq0ajCagOKRQD3C5R9V4gExqKhAJQKJQLG2pcjVSohIW6HQ4/nlmfy6trTbpfDszjO771cylJ2dfWZmZz878925YD9yioi+2qr+gOvzGy/W0tIiP/30UyhGCQAAAADwyp7H3377zf//yspKaWho6HaVqM2bN8uIESNMjhIAAAAA4LXi8YYbbhCfz+d0+tDViw0ePFhWrFhhcpQAAAAAAK8Vj3V1daKUktGjR8uuXbtk2LBh/udiYmIkJSXFtdtrTJgwQQYONDO7hw8fFpP0vXxM0svAtHHjxhltb/bs2UbbS0hIMNLOuXPn5JdffjHSFi6f/gHKhKSkJKOLQd9by/QV9Uy7++67jbZ3KTeSd+P7KRTfc4gMycnJRts7dOiQmDZy5Eij7eXn5xtt7/fffzfWVltbm7G20H/6yD9T69T9+/cbXQSmpqtTUVGRmLZu3Tqj7XV0dIjXGS0es7KyIuaNAQAAAACE+GqrH3/8cZ/PP/zww6EYLQAAAADAS8Xj008/3e1xa2urnD171jl09eqrr6Z4BAAAAACPCcmtOk6fPt2ta25ulqqqKpk2bZrxY4cBAAAAAB4tHnuTnZ0tr732Wo+9kgAAAAAA+4WteNT01U5PnDgRzlECAAAAAGw953HTpk09LqleX18vK1eulMLCwlCMEgAAAADgteJx7ty5Pe7jou/5OH36dHnzzTdDMUoAAAAAgNeKR+7zCAAAAACRJaTnPJ46dcrpAAAAAADeZrx4/Oeff6S4uFiSk5MlNTXV6fT/Fy5c6DwHAAAAAIjyw1b//vtvmTp1qhw/flyKiookJyfH6V9ZWSllZWWydetW2bFjhyQlJZkcLQAAAADAS8Xjyy+/LDExMVJbW+vscbz4uZkzZzp/33rrLZOjBQAAAAB46bDVzz//XJYvX96jcNSGDx8ub7zxhpSXl5scJQAAAADAa8Wjvpdjbm5uwOfz8vKkoaHB5CgBAAAAAF4rHvWFcQ4fPhzw+bq6Ohk6dKjJUQIAAAAAvFY8zpo1S1544QW5cOFCj+fOnz8vL774osyePdvkKAEAAAAAXrxgzqRJkyQ7O9u5XcfYsWNFKSUHDx6Ud9991ykgP/nkE5OjBAAAAAB4rXjMyMiQnTt3ypNPPilLlixxCkfN5/PJ7bffLitXrpTMzEyTowQAAAAAeK141EaNGiXffPONnD59Wqqrq51+1113nevnOk6fPl3i4uKMtLV9+3Yxfa6oSc3NzWLatGnTjLaXnp5utL1HH33USDuNjY3y3HPPGWkLl2fw4MHOD04m6O8ek/bu3Wu0vdjYWDHN9KkB+ogRk77//nuj7cEdHR0dTmdCU1OTmPTKK68Yba+kpERMM539zh/rTWlpaTHWVltbm7G20H/t7e3Wvm36QpombdiwQaKNz9D2Un++Q4wXj52SkpJkypQpoWoeAAAAAODVC+YAAAAAACITxSMAAAAAICiKRwAAAABAUBSPAAAAAADvF4/Hjx+XBx98UK655hrnKozjx4+XX3/91e3JAnARsgp4A1kF7EdOYauQXW3VBH27j8LCQrntttuc238MGzbMuf2HvpIrAHuQVcAbyCpgP3IKm1ldPL7++uuSmZkpa9as6XYfSQB2IauAN5BVwH7kFDaz+rDVTZs2yaRJk+Tee++VlJQUyc/Plw8//DDoDa31jd67dgDIKoD+r1dZpwLhx/YvbGZ18Xjo0CFZtWqVZGdny5YtW2TBggXy1FNPyUcffRTwNaWlpZKQkODv9J5LAGQVQP/Xq6xTgfBj+xc2s7p47OjokBtvvFFeffVV59fR+fPny+OPPy7vvfdewNcsWbJEzpw54++OHj0a1mkGohFZBSIzq6xTgfBjnQqbWV08pqWlybhx47r1y8nJkSNHjgR8TWxsrMTHx3frAIQWWQUiM6usU4HwY50Km1ldPOorrVZVVXXr98cff0hWVpZr0wSgJ7IKeANZBexHTmEzq4vHZ555RioqKpzDa2pqamTt2rXywQcfSHFxsduTBqALsgp4A1kF7EdOYTOri8fJkydLeXm5rFu3TvLy8mTZsmXy9ttvS1FRkduTBqALsgp4A1kF7EdOYTOr7/Oo3XXXXU4HwG5kFfAGsgrYj5zCVlbveQQAAAAA2IHiEQAAAADg/cNWr5RSyvnb0tJirM3W1lYxqa2tzWh77e3tYtr58+eNtnfu3Dmj7TU2Nhptp/Nzg/DpfM9Nvvems2D6c6Hv5WWa6e8T0+2ZRlbdeb9NfedqTU1NYvP6JRQ5tX2dajL3nW2R1fDywvtt+zo6VG3aPH2X0p5P2f6uXKFjx45JZmam25MBjzl69KhkZGS4PRlRhazicpDV8CKnuFxkNbzIKkKV04gvHvUvhidOnJAhQ4aIz+cLOJz+FVUXmfpNi4+PF69iPq6MjoP+FTw9PV0GDOCo7nAiq97k1ncOWXUHOfUushpdyKo3NXpgnRrxh63qN6A/e5D0gvJy8diJ+bh8CQkJBpcELhVZ9TY3vnPIaviRU+8jq9GBrHpbvMXrVHatAAAAAACCongEAAAAAARF8fh/sbGxUlJS4vz1MuYDkY7PuF0iZXnArEj5XETKfETavMCcSPlcMB/hE/EXzAEAAAAAXDn2PAIAAAAAgqJ4BAAAAAAERfEIAAAAAAiK4hEAAAAAEBTFIwAAAAAgqKgqHt955x0ZOXKkxMXFSUFBgezatavP4T/77DMZO3asM/z48ePl66+/FjeVlpbK5MmTZciQIZKSkiJz586VqqqqPl9TVlYmPp+vW6fnx01Lly7tMU36ffbSskBokVWyCvuRUztyqrFeRV/Iqh1ZXRoh279RUzxu2LBBnn32WedeNnv27JGJEyfKrFmz5OTJk70Ov2PHDnnggQfksccek7179zqFmu72798vbtm2bZsUFxdLRUWFfPvtt9La2iozZ86Uf//9t8/XxcfHS319vb/7888/xW25ubndpunnn38OOKyNywKhQ1bJKuxHTu3KqcZ6Fb0hq3ZlNTcStn9VlJgyZYoqLi72P25vb1fp6emqtLS01+Hvu+8+deedd3brV1BQoJ544glli5MnT+p7dKpt27YFHGbNmjUqISFB2aSkpERNnDjxkof3wrKAOWTVHmQVgZBTu5BVBEJW7VESIdu/UbHn8cKFC7J7926ZMWOGv9+AAQOcxzt37uz1Nbp/1+E1vacy0PBuOHPmjPN36NChfQ7X3NwsWVlZkpmZKffcc48cOHBA3FZdXS3p6ekyevRoKSoqkiNHjgQc1gvLAmaQVbIK+5FT+3KqsV7FxciqfVmtjoDt36goHk+dOiXt7e2Smprarb9+3NDQ0OtrdP/+DB9uHR0dsmjRIiksLJS8vLyAw11//fWyevVq+eKLL+TTTz91XnfzzTfLsWPHxC36fFN9LubmzZtl1apVUldXJ7fccos0NTV5clnAHLJKVmE/cmpXTjXWq+gNWbUrqwURsv070NWx47Lpcx/1Mc99HSutTZ061ek66eDk5OTI+++/L8uWLXNlCcyZM8f//wkTJjhh0r8Mbdy40TmuG4gkZBWwn5dzqrFeRbTwclbnRMj2b1QUj8nJyXLVVVfJX3/91a2/fjx8+PBeX6P792f4cFq4cKF8+eWX8uOPP0pGRka/Xjto0CDJz8+XmpoasUViYqKMGTMm4DTZvCxgFln9D1mFrcip3TnVWK9CI6t2ZzXRo9u/UXHYakxMjNx0002ydetWfz+9+1o/7vqrRFe6f9fhNX2F00DDh4NSyikcy8vL5bvvvpNRo0b1uw19+O6+ffskLS1NbKHPyaytrQ04TTYuC4QGWf0PWYWtyKndOdVYr0Ijq3Zntdmr278qSqxfv17FxsaqsrIyVVlZqebPn68SExNVQ0OD8/xDDz2knn/+ef/w27dvVwMHDlTLly9XBw8edK6QNGjQILVv3z7X5mHBggXOlVN/+OEHVV9f7+/Onj3rH+bi+XjppZfUli1bVG1trdq9e7e6//77VVxcnDpw4IBLc6HU4sWLnXmoq6tz3ucZM2ao5ORk5+qxXlkWCB2ySlZhP3JqT0411qsIhKzak9XFEbL9GzXFo7ZixQp17bXXqpiYGOfSxRUVFf7nbr31VvXII490G37jxo1qzJgxzvC5ubnqq6++Um7StX5vnb4dR6D5WLRokX+eU1NT1R133KH27Nmj3DRv3jyVlpbmTNOIESOcxzU1NZ5aFggtskpWYT9yakdONdar6AtZtSOr8yJk+9en/3F33ycAAAAAwHZRcc4jAAAAAODKUDwCAAAAAIKieAQAAAAABEXxCAAAAAAIiuIRAAAAABAUxSMAAAAAICiKRwAAAABAUBSPAAAAAICgKB4BAAAAAEFRPAIAAAAAgqJ4BAAAAABIMP8DKy4m/VsSIS8AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x1000 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualise the inputs/outputs from the quanv function\n",
        "l_inputs = inputs.cpu()\n",
        "n_samples = 4\n",
        "n_channels = 4\n",
        "fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
        "for k in range(n_samples):\n",
        "    axes[0, 0].set_ylabel(\"Input\")\n",
        "    if k != 0:\n",
        "        axes[0, k].yaxis.set_visible(False)\n",
        "    axes[0, k].imshow(l_inputs[k, 0, :, :], cmap=\"gray\")\n",
        "\n",
        "    # Plot all output channels\n",
        "    for c in range(n_channels):\n",
        "        axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
        "        if k != 0:\n",
        "            axes[c, k].yaxis.set_visible(False)\n",
        "        axes[c + 1, k].set_title(f\"{labels[c+(k*n_samples)]}\")\n",
        "        axes[c + 1, k].imshow(outputs[k, c, :, :], cmap=\"gray\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gBgKTzrVeel"
      },
      "source": [
        "### Create Data Loaders\n",
        "\n",
        "Data loaders for both the training and test/validation datasets are created here. In both cases, a random selection of n_train and n_test objects are taken from the full MNIST dataset.\n",
        "\n",
        "The indices of the selected objects are saved to a file (\"dataset_indices.pt\") so they can be reused at a later time if desired. The REGENERATE_INDICES_FILE should be set to *False* if a previously saved set of dataset indices is to be used and set to *True* if a new randomly selected set of indices should be used.\n",
        "\n",
        "Note that on colab, any saved index files should be downloaded to your local computer since colab will delete such files when the session is disconnected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fcJytqXzc71",
        "outputId": "17376eee-4137-45a2-b626-a45577ee8002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(train_subset)=1000\n",
            "len(test_subset)=200\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "os.chdir(\"Enter your current directory path here\")\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "REGENERATE_INDICES_FILE = True\n",
        "\n",
        "SUBSET_INDICES_FILE = Path(\"dataset_indices.pt\")\n",
        "# Randomly generate indexes for the training and test/validation\n",
        "# images from the overall dataset. This only needs to be done\n",
        "# once with subsequent runs reading the indices from the saved file.\n",
        "#\n",
        "if REGENERATE_INDICES_FILE is True:\n",
        "    train_indices = torch.randint(0, len(train_data), (n_train,))\n",
        "    test_indices = torch.randint(0, len(test_data), (n_test,))\n",
        "    torch.save({\"train_indices\": train_indices, \"test_indices\": test_indices},\n",
        "              SUBSET_INDICES_FILE)\n",
        "subset_indices_dict = torch.load(SUBSET_INDICES_FILE)\n",
        "\n",
        "train_subset = Subset(train_data, subset_indices_dict['train_indices'])\n",
        "test_subset = Subset(test_data, subset_indices_dict['test_indices'])\n",
        "\n",
        "train_loader = DataLoader(train_subset, shuffle=False, batch_size=batch_size)\n",
        "val_loader = DataLoader(test_subset, shuffle=False, batch_size=batch_size)\n",
        "print(f\"{len(train_subset)=}\")\n",
        "print(f\"{len(test_subset)=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImprovedUltraLightCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedUltraLightCNN, self).__init__()\n",
        "        \n",
        "        # Single convolutional layer with exactly 4 trainable parameters\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=1,\n",
        "            kernel_size=2,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=False\n",
        "        )\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "        self.fc1 = nn.Linear(36, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        \n",
        "        self._initialize_weights()\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='leaky_relu', a=0.1)\n",
        "        \n",
        "        nn.init.xavier_normal_(self.fc1.weight, gain=0.1)\n",
        "        nn.init.zeros_(self.fc1.bias)\n",
        "        nn.init.xavier_normal_(self.fc2.weight, gain=0.1)\n",
        "        nn.init.zeros_(self.fc2.bias)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if x.shape[1] == 3:\n",
        "            x = torch.mean(x, dim=1, keepdim=True)\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = F.leaky_relu(x, negative_slope=0.1)\n",
        "        \n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        x = F.leaky_relu(self.fc1(x), negative_slope=0.1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def count_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "    \n",
        "    def get_parameter_breakdown(self):\n",
        "        breakdown = {\n",
        "            'conv1.weight': self.conv1.weight.numel(),\n",
        "            'fc1.weight': self.fc1.weight.numel(),\n",
        "            'fc1.bias': self.fc1.bias.numel(),\n",
        "            'fc2.weight': self.fc2.weight.numel(),\n",
        "            'fc2.bias': self.fc2.bias.numel(),\n",
        "        }\n",
        "        breakdown['total'] = sum(breakdown.values())\n",
        "        return breakdown\n",
        "\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes=10, smoothing=0.1, dim=-1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.dim = dim\n",
        "    \n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
        "\n",
        "def get_improved_data_transforms():\n",
        "    return {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize(16),  # Slight oversampling\n",
        "            transforms.RandomCrop(14, padding=1),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229])  # ImageNet grayscale stats\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(14),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485], std=[0.229])\n",
        "        ])\n",
        "    }\n",
        "\n",
        "def train_model_with_improvements(model, train_loader, val_loader, epochs=50, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    \n",
        "    criterion = LabelSmoothingLoss(classes=10, smoothing=0.1)\n",
        "    \n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    \n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    \n",
        "    max_grad_norm = 1.0\n",
        "    \n",
        "    best_acc = 0.0\n",
        "    best_model_wts = None\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        \n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                loss.backward()\n",
        "                \n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "                \n",
        "                optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "        \n",
        "        model.eval()\n",
        "        val_corrects = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(labels)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "        \n",
        "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        print(f'Epoch {epoch+1}/{epochs} | '\n",
        "              f'Train Loss: {epoch_loss:.4f} | '\n",
        "              f'Train Acc: {epoch_acc:.4f} | '\n",
        "              f'Val Acc: {val_acc:.4f} | '\n",
        "              f'LR: {scheduler.get_last_lr()[0]:.6f}')\n",
        "        \n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = model.state_dict().copy()\n",
        "    \n",
        "    if best_model_wts is not None:\n",
        "        model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    print(f'Best validation accuracy: {best_acc:.4f}')\n",
        "    return model, best_acc\n",
        "\n",
        "def calculate_model_parameters():\n",
        "    model = ImprovedUltraLightCNN()\n",
        "    total_params = model.count_parameters()\n",
        "    breakdown = model.get_parameter_breakdown()\n",
        "    \n",
        "    print(f\"Total trainable parameters: {total_params:,}\")\n",
        "    print(\"Parameter breakdown:\")\n",
        "    for layer, params in breakdown.items():\n",
        "        if layer != 'total':\n",
        "            print(f\"  {layer}: {params:,} parameters\")\n",
        "    print(f\"  Total: {breakdown['total']:,} parameters\")\n",
        "    print(f\"Within 2000 parameter limit: {total_params <= 2000}\")\n",
        "    print(f\"Convolutional kernel parameters: {model.conv1.weight.numel()} (target: 4)\")\n",
        "    print(\"=\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbP76WEdhVF9"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDjf59GxR0PE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=0, lr=[0.003], 2025-12-04 21:52:00.543320\n",
            "Training [2%]\tLoss: 2.3037\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=1, lr=[0.003], 2025-12-04 21:52:03.121681\n",
            "Training [5%]\tLoss: 2.3029\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=2, lr=[0.003], 2025-12-04 21:52:05.825285\n",
            "Training [8%]\tLoss: 2.3026\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=3, lr=[0.003], 2025-12-04 21:52:08.780532\n",
            "Training [10%]\tLoss: 2.3024\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=4, lr=[0.003], 2025-12-04 21:52:11.518934\n",
            "Training [12%]\tLoss: 2.3023\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=5, lr=[0.003], 2025-12-04 21:52:14.259254\n",
            "Training [15%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=6, lr=[0.003], 2025-12-04 21:52:17.148894\n",
            "Training [18%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=7, lr=[0.003], 2025-12-04 21:52:19.860132\n",
            "Training [20%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=8, lr=[0.003], 2025-12-04 21:52:22.499743\n",
            "Training [22%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=9, lr=[0.003], 2025-12-04 21:52:25.505215\n",
            "Training [25%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=10, lr=[0.003], 2025-12-04 21:52:28.468013\n",
            "Training [28%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=11, lr=[0.003], 2025-12-04 21:52:31.425965\n",
            "Training [30%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=12, lr=[0.003], 2025-12-04 21:52:34.468544\n",
            "Training [32%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=13, lr=[0.003], 2025-12-04 21:52:37.136146\n",
            "Training [35%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=14, lr=[0.003], 2025-12-04 21:52:39.788361\n",
            "Training [38%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=15, lr=[0.003], 2025-12-04 21:52:42.954447\n",
            "Training [40%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=16, lr=[0.003], 2025-12-04 21:52:45.725121\n",
            "Training [42%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=17, lr=[0.003], 2025-12-04 21:52:48.543256\n",
            "Training [45%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=18, lr=[0.003], 2025-12-04 21:52:51.543290\n",
            "Training [48%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=19, lr=[0.003], 2025-12-04 21:52:54.693223\n",
            "Training [50%]\tLoss: 2.3022\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=20, lr=[0.003], 2025-12-04 21:52:57.418110\n",
            "Training [52%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=21, lr=[0.003], 2025-12-04 21:53:00.502516\n",
            "Training [55%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=22, lr=[0.003], 2025-12-04 21:53:03.217660\n",
            "Training [58%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=23, lr=[0.003], 2025-12-04 21:53:05.888614\n",
            "Training [60%]\tLoss: 2.3020\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=24, lr=[0.003], 2025-12-04 21:53:08.632296\n",
            "Training [62%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=25, lr=[0.003], 2025-12-04 21:53:11.483011\n",
            "Training [65%]\tLoss: 2.3021\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=26, lr=[0.003], 2025-12-04 21:53:14.162414\n",
            "Training [68%]\tLoss: 2.3020\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=27, lr=[0.003], 2025-12-04 21:53:16.855029\n",
            "Training [70%]\tLoss: 2.3020\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=28, lr=[0.003], 2025-12-04 21:53:19.526292\n",
            "Training [72%]\tLoss: 2.3020\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=29, lr=[0.003], 2025-12-04 21:53:22.278013\n",
            "Training [75%]\tLoss: 2.3020\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=30, lr=[0.003], 2025-12-04 21:53:24.973230\n",
            "Training [78%]\tLoss: 2.3020\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=31, lr=[0.003], 2025-12-04 21:53:27.620238\n",
            "Training [80%]\tLoss: 2.3019\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=32, lr=[0.003], 2025-12-04 21:53:30.423106\n",
            "Training [82%]\tLoss: 2.3020\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=33, lr=[0.003], 2025-12-04 21:53:33.290933\n",
            "Training [85%]\tLoss: 2.3019\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=34, lr=[0.003], 2025-12-04 21:53:36.009202\n",
            "Training [88%]\tLoss: 2.3019\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=35, lr=[0.003], 2025-12-04 21:53:38.669009\n",
            "Training [90%]\tLoss: 2.3018\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=36, lr=[0.003], 2025-12-04 21:53:41.422672\n",
            "Training [92%]\tLoss: 2.3019\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=37, lr=[0.003], 2025-12-04 21:53:44.441618\n",
            "Training [95%]\tLoss: 2.3018\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=38, lr=[0.003], 2025-12-04 21:53:47.675685\n",
            "Training [98%]\tLoss: 2.3017\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "epoch=39, lr=[0.003], 2025-12-04 21:53:50.928969\n",
            "Training [100%]\tLoss: 2.3017\n",
            "Saving model state to models\\ImgClass-Quanvolv.pth\n",
            "Accuracy on the validation set: 11.00%\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "dataset  = train_data\n",
        "\n",
        "# Initialize your QCNN model\n",
        "#cnn = QuantModel().to(device)\n",
        "cnn = ImprovedUltraLightCNN().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=initial_lr,\n",
        "                      momentum=0.9)  # Stochastic Gradient Descent optimizer\n",
        "\n",
        "# Create a learning rate scheduler\n",
        "# Here, we use StepLR which reduces the learning rate by a factor every step_size epochs\n",
        "#\n",
        "# Setting step_size = 1.0 will effectively disable the scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=1.0)\n",
        "\n",
        "train_loader = DataLoader(train_subset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "MODEL_NAME = \"ImgClass-Quanvolv.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "RESUME_TRAINING = False\n",
        "\n",
        "if RESUME_TRAINING is True:\n",
        "    print(f\"Restore model state from {MODEL_SAVE_PATH}\")\n",
        "    model_dict = torch.load(MODEL_SAVE_PATH)\n",
        "    initial_epoch = model_dict['epoch'] + 1\n",
        "    cnn.load_state_dict(model_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(model_dict['optimizer_state_dict'])\n",
        "    loss_list = model_dict['loss'].copy()\n",
        "else:\n",
        "    initial_epoch = 0\n",
        "    loss_list = []\n",
        "\n",
        "for epoch in range(initial_epoch, num_epochs):\n",
        "    cnn.train()\n",
        "    ct = datetime.datetime.now()\n",
        "    lr = scheduler.get_last_lr()\n",
        "    print(f\"{epoch=}, {lr=}, {ct}\")\n",
        "    running_loss = []\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()  # Zero the parameter gradients to avoid accumulation\n",
        "        outputs = cnn(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        running_loss.append(loss.item())\n",
        "        optimizer.step()  # Update the model parameters\n",
        "    loss_list.append(sum(running_loss)/len(running_loss))\n",
        "\n",
        "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(100. * (epoch + 1) / num_epochs, loss_list[-1]))\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': cnn.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss_list,\n",
        "    }, MODEL_SAVE_PATH)\n",
        "    print(f\"Saving model state to {MODEL_SAVE_PATH}\")\n",
        "\n",
        "    val_loader = DataLoader(test_subset, shuffle=False, batch_size=batch_size)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # Set the model to evaluation mode\n",
        "    cnn.eval()\n",
        "    with torch.inference_mode():\n",
        "        for data in val_loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = cnn(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')\n",
        "\n",
        "    # Decay Learning Rate\n",
        "    scheduler.step()\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 | Train Loss: 2.3031 | Train Acc: 0.0960 | Val Acc: 0.1100 | LR: 0.000999\n",
            "Epoch 2/50 | Train Loss: 2.3021 | Train Acc: 0.1050 | Val Acc: 0.1100 | LR: 0.000996\n",
            "Epoch 3/50 | Train Loss: 2.3000 | Train Acc: 0.1140 | Val Acc: 0.1100 | LR: 0.000991\n",
            "Epoch 4/50 | Train Loss: 2.2958 | Train Acc: 0.1160 | Val Acc: 0.1050 | LR: 0.000984\n",
            "Epoch 5/50 | Train Loss: 2.2876 | Train Acc: 0.1390 | Val Acc: 0.1400 | LR: 0.000976\n",
            "Epoch 6/50 | Train Loss: 2.2769 | Train Acc: 0.1590 | Val Acc: 0.1500 | LR: 0.000965\n",
            "Epoch 7/50 | Train Loss: 2.2657 | Train Acc: 0.1550 | Val Acc: 0.1850 | LR: 0.000952\n",
            "Epoch 8/50 | Train Loss: 2.2545 | Train Acc: 0.1730 | Val Acc: 0.1700 | LR: 0.000938\n",
            "Epoch 9/50 | Train Loss: 2.2461 | Train Acc: 0.1690 | Val Acc: 0.1750 | LR: 0.000922\n",
            "Epoch 10/50 | Train Loss: 2.2422 | Train Acc: 0.1720 | Val Acc: 0.1700 | LR: 0.000905\n",
            "Epoch 11/50 | Train Loss: 2.2354 | Train Acc: 0.1770 | Val Acc: 0.1600 | LR: 0.000885\n",
            "Epoch 12/50 | Train Loss: 2.2313 | Train Acc: 0.1760 | Val Acc: 0.1600 | LR: 0.000864\n",
            "Epoch 13/50 | Train Loss: 2.2238 | Train Acc: 0.1780 | Val Acc: 0.1750 | LR: 0.000842\n",
            "Epoch 14/50 | Train Loss: 2.2231 | Train Acc: 0.1820 | Val Acc: 0.1650 | LR: 0.000819\n",
            "Epoch 15/50 | Train Loss: 2.2215 | Train Acc: 0.1870 | Val Acc: 0.1750 | LR: 0.000794\n",
            "Epoch 16/50 | Train Loss: 2.2186 | Train Acc: 0.1900 | Val Acc: 0.1900 | LR: 0.000768\n",
            "Epoch 17/50 | Train Loss: 2.2151 | Train Acc: 0.2000 | Val Acc: 0.1850 | LR: 0.000741\n",
            "Epoch 18/50 | Train Loss: 2.2158 | Train Acc: 0.1800 | Val Acc: 0.2150 | LR: 0.000713\n",
            "Epoch 19/50 | Train Loss: 2.2118 | Train Acc: 0.1980 | Val Acc: 0.1950 | LR: 0.000684\n",
            "Epoch 20/50 | Train Loss: 2.2089 | Train Acc: 0.2180 | Val Acc: 0.2100 | LR: 0.000655\n",
            "Epoch 21/50 | Train Loss: 2.2030 | Train Acc: 0.2090 | Val Acc: 0.2000 | LR: 0.000624\n",
            "Epoch 22/50 | Train Loss: 2.2051 | Train Acc: 0.2040 | Val Acc: 0.2050 | LR: 0.000594\n",
            "Epoch 23/50 | Train Loss: 2.2048 | Train Acc: 0.1990 | Val Acc: 0.2100 | LR: 0.000563\n",
            "Epoch 24/50 | Train Loss: 2.1995 | Train Acc: 0.1960 | Val Acc: 0.2150 | LR: 0.000531\n",
            "Epoch 25/50 | Train Loss: 2.2019 | Train Acc: 0.2080 | Val Acc: 0.2200 | LR: 0.000500\n",
            "Epoch 26/50 | Train Loss: 2.1943 | Train Acc: 0.2110 | Val Acc: 0.2200 | LR: 0.000469\n",
            "Epoch 27/50 | Train Loss: 2.1981 | Train Acc: 0.2030 | Val Acc: 0.2150 | LR: 0.000437\n",
            "Epoch 28/50 | Train Loss: 2.1939 | Train Acc: 0.2110 | Val Acc: 0.2300 | LR: 0.000406\n",
            "Epoch 29/50 | Train Loss: 2.1959 | Train Acc: 0.2190 | Val Acc: 0.2050 | LR: 0.000376\n",
            "Epoch 30/50 | Train Loss: 2.1900 | Train Acc: 0.2150 | Val Acc: 0.2200 | LR: 0.000345\n",
            "Epoch 31/50 | Train Loss: 2.1841 | Train Acc: 0.2140 | Val Acc: 0.2200 | LR: 0.000316\n",
            "Epoch 32/50 | Train Loss: 2.1938 | Train Acc: 0.2130 | Val Acc: 0.2150 | LR: 0.000287\n",
            "Epoch 33/50 | Train Loss: 2.1924 | Train Acc: 0.2150 | Val Acc: 0.2150 | LR: 0.000259\n",
            "Epoch 34/50 | Train Loss: 2.1886 | Train Acc: 0.2230 | Val Acc: 0.2150 | LR: 0.000232\n",
            "Epoch 35/50 | Train Loss: 2.1891 | Train Acc: 0.2240 | Val Acc: 0.2100 | LR: 0.000206\n",
            "Epoch 36/50 | Train Loss: 2.1885 | Train Acc: 0.2160 | Val Acc: 0.2000 | LR: 0.000181\n",
            "Epoch 37/50 | Train Loss: 2.1823 | Train Acc: 0.2080 | Val Acc: 0.2100 | LR: 0.000158\n",
            "Epoch 38/50 | Train Loss: 2.1866 | Train Acc: 0.2200 | Val Acc: 0.2050 | LR: 0.000136\n",
            "Epoch 39/50 | Train Loss: 2.1855 | Train Acc: 0.2160 | Val Acc: 0.1950 | LR: 0.000115\n",
            "Epoch 40/50 | Train Loss: 2.1817 | Train Acc: 0.2200 | Val Acc: 0.1950 | LR: 0.000095\n",
            "Epoch 41/50 | Train Loss: 2.1841 | Train Acc: 0.2240 | Val Acc: 0.1900 | LR: 0.000078\n",
            "Epoch 42/50 | Train Loss: 2.1872 | Train Acc: 0.2210 | Val Acc: 0.1900 | LR: 0.000062\n",
            "Epoch 43/50 | Train Loss: 2.1840 | Train Acc: 0.2220 | Val Acc: 0.1900 | LR: 0.000048\n",
            "Epoch 44/50 | Train Loss: 2.1842 | Train Acc: 0.2210 | Val Acc: 0.1900 | LR: 0.000035\n",
            "Epoch 45/50 | Train Loss: 2.1820 | Train Acc: 0.2160 | Val Acc: 0.1900 | LR: 0.000024\n",
            "Epoch 46/50 | Train Loss: 2.1852 | Train Acc: 0.2210 | Val Acc: 0.1900 | LR: 0.000016\n",
            "Epoch 47/50 | Train Loss: 2.1813 | Train Acc: 0.2140 | Val Acc: 0.1900 | LR: 0.000009\n",
            "Epoch 48/50 | Train Loss: 2.1834 | Train Acc: 0.2140 | Val Acc: 0.1900 | LR: 0.000004\n",
            "Epoch 49/50 | Train Loss: 2.1852 | Train Acc: 0.2200 | Val Acc: 0.1900 | LR: 0.000001\n",
            "Epoch 50/50 | Train Loss: 2.1820 | Train Acc: 0.2320 | Val Acc: 0.1900 | LR: 0.000000\n",
            "Best validation accuracy: 0.2300\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = ImprovedUltraLightCNN()\n",
        "transforms = get_improved_data_transforms()\n",
        "trained_model, best_acc = train_model_with_improvements(\n",
        "    model, train_loader, val_loader, epochs=40, device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8H77i8ehkdq"
      },
      "source": [
        "### Model Inference\n",
        "\n",
        "The problem with the 'IndexError' exception has now been fixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DnoVGSNNwmu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on the validation set: 23.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#accuracy\n",
        "\n",
        "# Use a small subset of the full validation dataset\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "\n",
        "K = n_test # enter your length here\n",
        "subsample_train_indices = torch.randperm(len(val_set))[:K]\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, sampler=SubsetRandomSampler(subsample_train_indices))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "# Set the model to evaluation mode\n",
        "cnn.eval()\n",
        "with torch.inference_mode():\n",
        "    for data in val_loader:\n",
        "        images, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 1, 13, 13]               4\n",
            "         MaxPool2d-2              [-1, 1, 6, 6]               0\n",
            "            Linear-3                   [-1, 50]           1,850\n",
            "           Dropout-4                   [-1, 50]               0\n",
            "            Linear-5                   [-1, 10]             510\n",
            "================================================================\n",
            "Total params: 2,364\n",
            "Trainable params: 2,364\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.01\n",
            "Estimated Total Size (MB): 0.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1, 14, 14))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "QCNN",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
